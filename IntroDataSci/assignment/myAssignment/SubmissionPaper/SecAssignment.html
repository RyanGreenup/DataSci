<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2019-11-19 Tue 13:31 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Intro Data Sci Assignment</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="ryan" />
<style type="text/css">
<!-- [CDATA] -->
* Gong
Found this on github
#+BEGIN_SRC css


/*! normalize.css v4.1.1 | MIT License | github.com/necolas/normalize.css */html{font-family:sans-serif;line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block}audio:not([controls]){display:none;height:0}progress{vertical-align:baseline}[hidden],template{display:none}a{background-color:transparent;-webkit-text-decoration-skip:objects}a:active,a:hover{outline-width:0}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:inherit;font-weight:bolder}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}svg:not(:root){overflow:hidden}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}button,input,optgroup,select,textarea{font:inherit;margin:0}optgroup{font-weight:700}button,input{overflow:visible}button,select{text-transform:none}[type=reset],[type=submit],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}body{color:#000;background-color:#fff}.org-alert-high{color:#ff8c00;font-weight:700}.org-alert-low{color:#00008b}.org-alert-moderate{color:gold;font-weight:700}.org-alert-saved-fringe{background-color:#f2f2f2}.org-alert-trivial{color:Dark purple}.org-alert-urgent{color:red;font-weight:700}.org-anzu-match-1{color:#000;background-color:#7fffd4}.org-anzu-match-2{color:#000;background-color:#00ff7f}.org-anzu-match-3{color:#000;background-color:#ff0}.org-anzu-mode-line,.org-anzu-mode-line-no-match{color:#008b00;font-weight:700}.org-anzu-replace-highlight{color:#b0e2ff;background-color:#cd00cd}.org-anzu-replace-to{color:red}.org-bbdb-field-name{color:sienna}.org-bbdb-name{color:#00f}.org-bbdb-organization{color:#b22222}.org-beacon-fallback-background{background-color:#000}.org-biblio-results-header{color:#483d8b;font-size:150%;font-weight:700}.org-bold{font-weight:700}.org-bold-italic{font-weight:700;font-style:italic}.org-bookmark-menu-bookmark{font-weight:700}.org-bookmark-menu-heading{color:#228b22}.org-buffer-menu-buffer{font-weight:700}.org-builtin{color:#483d8b}.org-button{color:#3a5fcd;text-decoration:underline}.org-c-annotation{color:#008b8b}.org-cal-china-x-general-holiday{background-color:#228b22}.org-cal-china-x-important-holiday{background-color:#8b0000}.org-calendar-iso-week{color:pink;font-weight:700}.org-calendar-iso-week-header{color:#0ff}.org-calendar-month-header{color:#00f}.org-calendar-today{text-decoration:underline}.org-calendar-weekday-header{color:#008b8b}.org-calendar-weekend-header{color:#b22222}.org-comint-highlight-input{font-weight:700}.org-comint-highlight-prompt{color:#0000cd}.org-comment,.org-comment-delimiter{color:#b22222}.org-compilation-column-number{color:#8b2252}.org-compilation-error{color:red;font-weight:700}.org-compilation-info{color:#228b22;font-weight:700}.org-compilation-line-number{color:#a020f0}.org-compilation-mode-line-exit{color:#228b22;font-weight:700}.org-compilation-mode-line-fail{color:red;font-weight:700}.org-compilation-mode-line-run,.org-compilation-warning{color:#ff8c00;font-weight:700}.org-completions-annotations{font-style:italic}.org-completions-first-difference{font-weight:700}.org-constant{color:#008b8b}.org-cursor{background-color:#eead0e}.org-custom-button{color:#000;background-color:#d3d3d3}.org-custom-button-mouse{color:#000;background-color:#e5e5e5}.org-custom-button-pressed{color:#000;background-color:#d3d3d3}.org-custom-button-pressed-unraised{color:#8b008b;text-decoration:underline}.org-custom-button-unraised{text-decoration:underline}.org-custom-changed{color:#fff;background-color:#00f}.org-custom-comment{background-color:#d9d9d9}.org-custom-comment-tag{color:#00008b}.org-custom-face-tag{color:#00f;font-weight:700}.org-custom-group-subtitle{font-weight:700}.org-custom-group-tag{color:#00f;font-size:120%;font-weight:700}.org-custom-group-tag-1{color:red;font-size:120%;font-weight:700}.org-custom-invalid{color:#ff0;background-color:red}.org-custom-link{color:#3a5fcd;text-decoration:underline}.org-custom-modified{color:#fff;background-color:#00f}.org-custom-rogue{color:pink;background-color:#000}.org-custom-saved{text-decoration:underline}.org-custom-set{color:#00f;background-color:#fff}.org-custom-state{color:#006400}.org-custom-themed{color:#fff;background-color:#00f}.org-custom-variable-button{font-weight:700;text-decoration:underline}.org-custom-variable-tag{color:#00f;font-weight:700}.org-custom-visibility{color:#3a5fcd;font-size:80%;text-decoration:underline}.org-diary{color:red}.org-diary-anniversary{color:#a020f0}.org-diary-time{color:sienna}.org-dired-async-failures{color:red}.org-dired-async-message{color:#ff0}.org-dired-async-mode-message{color:gold}.org-dired-directory{color:#00f}.org-dired-flagged{color:red;font-weight:700}.org-dired-header{color:#228b22}.org-dired-ignored{color:#7f7f7f}.org-dired-mark{color:#008b8b}.org-dired-marked{color:#ff8c00;font-weight:700}.org-dired-perm-write{color:#b22222}.org-dired-symlink{color:#a020f0}.org-dired-warning{color:red;font-weight:700}.org-doc{color:#8b2252}.org-eldoc-highlight-function-argument{font-weight:700}.org-epa-field-body{font-style:italic}.org-epa-field-name,.org-epa-mark{font-weight:700}.org-epa-mark{color:red}.org-epa-string{color:#00008b}.org-epa-validity-disabled{font-style:italic}.org-epa-validity-high{font-weight:700}.org-epa-validity-low,.org-epa-validity-medium{font-style:italic}.org-error{color:red;font-weight:700}.org-escape-glyph{color:brown}.org-evil-ex-commands{font-style:italic;text-decoration:underline}.org-evil-ex-info{color:red;font-style:italic}.org-evil-ex-lazy-highlight{background-color:#afeeee}.org-evil-ex-search{color:#b0e2ff;background-color:#cd00cd}.org-evil-ex-substitute-matches{background-color:#afeeee}.org-evil-ex-substitute-replacement{color:red;text-decoration:underline}.org-ffap{background-color:#b4eeb4}.org-file-name-shadow{color:#7f7f7f}.org-flycheck-error{text-decoration:underline}.org-flycheck-error-list-checker-name{color:#00f}.org-flycheck-error-list-column-number{color:#008b8b}.org-flycheck-error-list-error{color:red;font-weight:700}.org-flycheck-error-list-filename{color:sienna}.org-flycheck-error-list-highlight{background-color:#b4eeb4}.org-flycheck-error-list-id,.org-flycheck-error-list-id-with-explainer{color:#228b22}.org-flycheck-error-list-info{color:#228b22;font-weight:700}.org-flycheck-error-list-line-number{color:#008b8b}.org-flycheck-error-list-warning{color:#ff8c00;font-weight:700}.org-flycheck-fringe-error{color:red;font-weight:700}.org-flycheck-fringe-info{color:#228b22;font-weight:700}.org-flycheck-fringe-warning{color:#ff8c00;font-weight:700}.org-flycheck-info,.org-flycheck-warning,.org-flyspell-duplicate,.org-flyspell-incorrect{text-decoration:underline}.org-fringe{background-color:#f2f2f2}.org-function-name{color:#00f}.org-glyphless-char{font-size:60%}.org-golden-ratio-scroll-highlight-line{color:#fff;background-color:#53868b;font-weight:700}.org-header-line{color:#333;background-color:#e5e5e5}.org-helm-action{text-decoration:underline}.org-helm-bookmark-addressbook{color:tomato}.org-helm-bookmark-directory{color:#8b0000;background-color:#d3d3d3}.org-helm-bookmark-file{color:#00b2ee}.org-helm-bookmark-file-not-found{color:#6c7b8b}.org-helm-bookmark-gnus{color:#f0f}.org-helm-bookmark-info{color:#0f0}.org-helm-bookmark-man{color:#8b5a00}.org-helm-bookmark-w3m{color:#ff0}.org-helm-buffer-archive{color:gold}.org-helm-buffer-directory{color:#8b0000;background-color:#d3d3d3}.org-helm-buffer-file{color:#483d8b}.org-helm-buffer-modified{color:#b22222}.org-helm-buffer-not-saved{color:#ee6363}.org-helm-buffer-process{color:#cd6839}.org-helm-buffer-saved-out{color:red;background-color:#000}.org-helm-buffer-size{color:#708090}.org-helm-candidate-number,.org-helm-candidate-number-suspended{color:#000;background-color:#faffb5}.org-helm-delete-async-message{color:#ff0}.org-helm-etags-file{color:#8b814c;text-decoration:underline}.org-helm-ff-denied{color:red;background-color:#000}.org-helm-ff-directory{color:#8b0000;background-color:#d3d3d3}.org-helm-ff-dirs{color:#00f}.org-helm-ff-dotted-directory{color:#000;background-color:#696969}.org-helm-ff-dotted-symlink-directory{color:#ff8c00;background-color:#696969}.org-helm-ff-executable{color:#0f0}.org-helm-ff-file{color:#483d8b}.org-helm-ff-invalid-symlink{color:#000;background-color:red}.org-helm-ff-pipe{color:#ff0;background-color:#000}.org-helm-ff-prefix{color:#000;background-color:#ff0}.org-helm-ff-socket{color:#ff1493}.org-helm-ff-suid{color:#fff;background-color:red}.org-helm-ff-symlink{color:#b22222}.org-helm-ff-truename{color:#8b2252}.org-helm-grep-cmd-line{color:#228b22}.org-helm-grep-file{color:#8a2be2;text-decoration:underline}.org-helm-grep-finish{color:#0f0}.org-helm-grep-lineno{color:#ff7f00}.org-helm-grep-match{color:#b00000}.org-helm-header{color:#333;background-color:#e5e5e5}.org-helm-header-line-left-margin{color:#000;background-color:#ff0}.org-helm-helper{color:#333;background-color:#e5e5e5}.org-helm-history-deleted{color:#000;background-color:red}.org-helm-history-remote{color:#ff6a6a}.org-helm-lisp-completion-info{color:red}.org-helm-lisp-show-completion{background-color:#2f4f4f}.org-helm-locate-finish{color:#0f0}.org-helm-m-x-key{color:orange;text-decoration:underline}.org-helm-match{color:#b00000}.org-helm-match-item{color:#b0e2ff;background-color:#cd00cd}.org-helm-minibuffer-prompt{color:#0000cd}.org-helm-moccur-buffer{color:#00ced1;text-decoration:underline}.org-helm-non-file-buffer{font-style:italic}.org-helm-prefarg{color:red}.org-helm-resume-need-update{background-color:red}.org-helm-selection{background-color:#097209}.org-helm-selection-line{background-color:#b4eeb4}.org-helm-separator{color:#ffbfb5}.org-helm-source-header{color:#000;background-color:#abd7f0;font-size:130%;font-weight:700}.org-helm-visible-mark{background-color:#d1f5ea}.org-help-argument-name{font-style:italic}.org-highlight{background-color:#b4eeb4}.org-highlight-indent-guides-character{color:#e6e6e6}.org-highlight-indent-guides-even{background-color:#e6e6e6}.org-highlight-indent-guides-odd{background-color:#f3f3f3}.org-highlight-indent-guides-stack-character{color:#ccc}.org-highlight-indent-guides-stack-even{background-color:#ccc}.org-highlight-indent-guides-stack-odd{background-color:#d9d9d9}.org-highlight-indent-guides-top-character{color:#b3b3b3}.org-highlight-indent-guides-top-even{background-color:#b3b3b3}.org-highlight-indent-guides-top-odd{background-color:silver}.org-highlight-numbers-number{color:#008b8b}.org-hl-line{background-color:#b4eeb4}.org-holiday{background-color:pink}.org-hydra-face-amaranth{color:#e52b50;font-weight:700}.org-hydra-face-blue{color:#00f;font-weight:700}.org-hydra-face-pink{color:#ff6eb4;font-weight:700}.org-hydra-face-red{color:red;font-weight:700}.org-hydra-face-teal{color:#367588;font-weight:700}.org-ido-first-match{font-weight:700}.org-ido-incomplete-regexp{color:red;font-weight:700}.org-ido-indicator{color:#ff0;background-color:red}.org-ido-only-match{color:#228b22}.org-ido-subdir{color:red}.org-ido-virtual{color:#483d8b}.org-info-header-node{color:brown;font-weight:700;font-style:italic}.org-info-header-xref{color:#3a5fcd;text-decoration:underline}.org-info-index-match{background-color:#ff0}.org-info-menu-header{font-weight:700}.org-info-menu-star{color:red}.org-info-node{color:brown;font-weight:700;font-style:italic}.org-info-title-1{font-size:172%;font-weight:700}.org-info-title-2{font-size:144%;font-weight:700}.org-info-title-3{font-size:120%;font-weight:700}.org-info-title-4{font-weight:700}.org-info-xref{color:#3a5fcd;text-decoration:underline}.org-isearch{color:#b0e2ff;background-color:#cd00cd}.org-isearch-fail{background-color:#ffc1c1}.org-italic{font-style:italic}.org-keyword{color:#a020f0}.org-lazy-highlight{background-color:#afeeee}.org-link{color:#3a5fcd;text-decoration:underline}.org-link-visited{color:#8b008b;text-decoration:underline}.org-lv-separator{background-color:#ccc}.org-match{background-color:#ff0}.org-mcXcursor-bar{background-color:#000}.org-mcXregion{background-color:gtk_selection_bg_color}.org-me-dired-dim-0{color:#b3b3b3}.org-me-dired-dim-1{color:#7f7f7f}.org-me-dired-executable{color:#0f0}.org-message-cited-text{color:red}.org-message-header-cc{color:#191970}.org-message-header-name{color:#6495ed}.org-message-header-newsgroups{color:#00008b;font-weight:700;font-style:italic}.org-message-header-other{color:#4682b4}.org-message-header-subject{color:navy;font-weight:700}.org-message-header-to{color:#191970;font-weight:700}.org-message-header-xheader{color:#00f}.org-message-mml{color:#228b22}.org-message-separator{color:brown}.org-minibuffer-prompt{color:#0000cd}.org-mm-command-output{color:#cd0000}.org-mode-line{color:#000;background-color:#bfbfbf}.org-mode-line-buffer-id,.org-mode-line-buffer-id-inactive,.org-mode-line-emphasis{font-weight:700}.org-mode-line-inactive{color:#333;background-color:#e5e5e5}.org-mu4e-attach-number{color:sienna;font-weight:700}.org-mu4e-cited-1{color:#483d8b;font-style:italic}.org-mu4e-cited-2{color:#5cacee;font-style:italic}.org-mu4e-cited-3{color:sienna;font-style:italic}.org-mu4e-cited-4{color:#a020f0;font-style:italic}.org-mu4e-cited-5,.org-mu4e-cited-6{color:#b22222;font-style:italic}.org-mu4e-cited-7{color:#228b22;font-style:italic}.org-mu4e-compose-header,.org-mu4e-compose-separator{color:brown;font-style:italic}.org-mu4e-contact{color:sienna}.org-mu4e-context{color:#006400;font-weight:700}.org-mu4e-draft{color:#8b2252}.org-mu4e-flagged{color:#008b8b;font-weight:700}.org-mu4e-footer{color:#b22222}.org-mu4e-forwarded{color:#483d8b}.org-mu4e-header{color:#000;background-color:#fff}.org-mu4e-header-highlight{background-color:#000;font-weight:700;text-decoration:underline}.org-mu4e-header-key{color:#6495ed;font-weight:700}.org-mu4e-header-marks{color:#483d8b}.org-mu4e-header-title,.org-mu4e-header-value{color:#228b22}.org-mu4e-highlight{background-color:#b4eeb4}.org-mu4e-link{color:#3a5fcd;text-decoration:underline}.org-mu4e-modeline{color:#8b4500;font-weight:700}.org-mu4e-moved{color:#b22222;font-style:italic}.org-mu4e-ok{color:#b22222;font-weight:700}.org-mu4e-region-code{background-color:#2f4f4f}.org-mu4e-replied,.org-mu4e-special-header-value{color:#483d8b}.org-mu4e-system{color:#b22222;font-style:italic}.org-mu4e-title{color:#228b22;font-weight:700}.org-mu4e-trashed{color:#b22222;text-decoration:line-through}.org-mu4e-unread{color:#a020f0;font-weight:700}.org-mu4e-url-number{color:#008b8b;font-weight:700}.org-mu4e-view-body{color:#000;background-color:#fff}.org-mu4e-warning{color:red;font-weight:700}.org-next-error{background-color:gtk_selection_bg_color}.org-nobreak-space{color:brown;text-decoration:underline}.org-org-agenda-calendar-event,.org-org-agenda-calendar-sexp{color:#000;background-color:#fff}.org-org-agenda-clocking{background-color:#ff0}.org-org-agenda-column-dateline{background-color:#e5e5e5}.org-org-agenda-current-time{color:#b8860b}.org-org-agenda-date{color:#00f}.org-org-agenda-date-today{color:#00f;font-weight:700;font-style:italic}.org-org-agenda-date-weekend{color:#00f;font-weight:700}.org-org-agenda-diary{color:#000;background-color:#fff}.org-org-agenda-dimmed-todo{color:#7f7f7f}.org-org-agenda-done{color:#228b22}.org-org-agenda-filter-category,.org-org-agenda-filter-effort,.org-org-agenda-filter-regexp,.org-org-agenda-filter-tags{color:#000;background-color:#bfbfbf}.org-org-agenda-restriction-lock{background-color:#eee}.org-org-agenda-structure{color:#00f}.org-org-archived{color:#7f7f7f}.org-org-block{color:#7f7f7f}.org-org-block-begin-line,.org-org-block-end-line{color:#b22222}.org-org-checkbox{font-weight:700}.org-org-checkbox-statistics-done{color:#228b22;font-weight:700}.org-org-checkbox-statistics-todo{color:red;font-weight:700}.org-org-clock-overlay{color:#000;background-color:#d3d3d3}.org-org-code{color:#7f7f7f}.org-org-column,.org-org-column-title{background-color:#e5e5e5}.org-org-column-title{font-weight:700;text-decoration:underline}.org-org-date{color:#bfaf87;text-decoration:underline}.org-org-date-selected{color:red}.org-org-default{color:#000;background-color:#fff}.org-org-document-info{color:#191970}.org-org-document-info-keyword{color:#7f7f7f}.org-org-document-title{color:#191970;font-weight:700}.org-org-done{color:#228b22;font-weight:700}.org-org-drawer{color:#00f}.org-org-ellipsis{color:#b8860b;text-decoration:underline}.org-org-footnote{color:#96b4cd;text-decoration:underline}.org-org-formula{color:#b22222}.org-org-habit-alert{background-color:#f5f946}.org-org-habit-alert-future{background-color:#fafca9}.org-org-habit-clear{background-color:#8270f9}.org-org-habit-clear-future{background-color:#d6e4fc}.org-org-habit-overdue{background-color:#f9372d}.org-org-habit-overdue-future{background-color:#fc9590}.org-org-habit-ready{background-color:#4df946}.org-org-habit-ready-future{background-color:#acfca9}.org-org-headline-done{color:#bc8f8f}.org-org-hide{color:#fff}.org-org-latex-and-related{color:#8b4513}.org-org-level-1{color:#edd1c5}.org-org-level-2{color:#ebebb7}.org-org-level-3{color:#cce8cc}.org-org-level-4{color:#c9deec}.org-org-level-5{color:#dce3e8}.org-org-level-6{color:#dde6dd}.org-org-level-7{color:#e8e8ce}.org-org-level-8{color:#e8dedb}.org-org-link{color:#c5d2dc;text-decoration:underline}.org-org-list-dt{font-weight:700}.org-org-macro{color:#8b4513}.org-org-meta-line{color:#b22222}.org-org-mode-line-clock{color:#000;background-color:#bfbfbf}.org-org-mode-line-clock-overrun{color:#000;background-color:red}.org-org-priority{color:#a020f0}.org-org-quote{color:#7f7f7f}.org-org-ref-acronym{color:#ee7600;text-decoration:underline}.org-org-ref-cite{color:#c3d5c3;text-decoration:underline}.org-org-ref-glossary{color:#8968cd;text-decoration:underline}.org-org-ref-label{color:#8b008b;text-decoration:underline}.org-org-ref-ref{color:#e1cc96;text-decoration:underline}.org-org-scheduled{color:#006400}.org-org-scheduled-previously{color:#b22222}.org-org-scheduled-today{color:#006400}.org-org-sexp-date{color:#a020f0}.org-org-special-keyword{color:#88949f}.org-org-table{color:#00f}.org-org-tag,.org-org-tag-group{font-weight:700}.org-org-target{text-decoration:underline}.org-org-time-grid{color:#b8860b}.org-org-todo{color:red;font-weight:700}.org-org-upcoming-deadline{color:#b22222}.org-org-verbatim,.org-org-verse{color:#7f7f7f}.org-org-warning{color:red;font-weight:700}.org-outline-1{color:#00f}.org-outline-2{color:sienna}.org-outline-3{color:#a020f0}.org-outline-4{color:#b22222}.org-outline-5{color:#228b22}.org-outline-6{color:#008b8b}.org-outline-7{color:#483d8b}.org-outline-8{color:#8b2252}.org-package-description{color:#000;background-color:#fff}.org-package-name{color:#3a5fcd;text-decoration:underline}.org-package-status-avail-obso{color:#b22222}.org-package-status-available{color:#000;background-color:#fff}.org-package-status-built-in{color:#483d8b}.org-package-status-dependency{color:#b22222}.org-package-status-disabled{color:red;font-weight:700}.org-package-status-external{color:#483d8b}.org-package-status-held{color:#008b8b}.org-package-status-incompat,.org-package-status-installed{color:#b22222}.org-package-status-unsigned{color:red;font-weight:700}.org-pdf-isearch-batch{background-color:#ff0}.org-pdf-isearch-lazy{background-color:#afeeee}.org-pdf-isearch-match{color:#b0e2ff;background-color:#cd00cd}.org-pdf-occur-document{color:#8b2252}.org-pdf-occur-page{color:#228b22}.org-pdf-view-rectangle{background-color:#b4eeb4}.org-pdf-view-region{background-color:gtk_selection_bg_color}.org-powerline-active0{color:#000;background-color:#bfbfbf}.org-powerline-active1{color:#fff;background-color:#2b2b2b}.org-powerline-active2{color:#fff;background-color:#666}.org-powerline-inactive0{color:#333;background-color:#e5e5e5}.org-powerline-inactive1{color:#333;background-color:#1c1c1c}.org-powerline-inactive2{color:#333;background-color:#333}.org-preprocessor{color:#483d8b}.org-query-replace{color:#b0e2ff;background-color:#cd00cd}.org-rainbow-delimiters-depth-1{color:#ffdead}.org-rainbow-delimiters-depth-2{color:#00bfff}.org-rainbow-delimiters-depth-3{color:#ffdead}.org-rainbow-delimiters-depth-4{color:#00bfff}.org-rainbow-delimiters-depth-5{color:#ffdead}.org-rainbow-delimiters-depth-6{color:#00bfff}.org-rainbow-delimiters-depth-7{color:#ffdead}.org-rainbow-delimiters-depth-8{color:#00bfff}.org-rainbow-delimiters-depth-9{color:#ffdead}.org-rainbow-delimiters-unmatched{color:#88090b}.org-reb-match-0{background-color:#add8e6}.org-reb-match-1{background-color:#7fffd4}.org-reb-match-2{background-color:#00ff7f}.org-reb-match-3{background-color:#ff0}.org-rectangle-preview{background-color:gtk_selection_bg_color}.org-regexp-grouping-backslash,.org-regexp-grouping-construct{font-weight:700}.org-region{background-color:gtk_selection_bg_color}.org-secondary-selection{background-color:#ff0}.org-semantic-highlight-edits,.org-semantic-highlight-func-current-tag{background-color:#e5e5e5}.org-semantic-unmatched-syntax{text-decoration:underline}.org-sgml-namespace{color:#483d8b}.org-sh-escaped-newline{color:#8b2252}.org-sh-heredoc{color:#ee0}.org-sh-quoted-exec{color:#f0f}.org-shadow{color:#7f7f7f}.org-show-paren-match{background-color:#40e0d0}.org-show-paren-mismatch{color:#fff;background-color:#a020f0}.org-sp-pair-overlay,.org-sp-show-pair-enclosing{background-color:#b4eeb4}.org-sp-show-pair-match{background-color:#40e0d0}.org-sp-show-pair-mismatch{color:#fff;background-color:#a020f0}.org-sp-wrap-overlay{background-color:#b4eeb4}.org-sp-wrap-overlay-closing-pair{color:red;background-color:#b4eeb4}.org-sp-wrap-overlay-opening-pair{color:#0f0;background-color:#b4eeb4}.org-sp-wrap-tag-overlay{background-color:#b4eeb4}.org-spaceline-flycheck-error{color:#fc5c94;background-color:#333}.org-spaceline-flycheck-info{color:#8de6f7;background-color:#333}.org-spaceline-flycheck-warning{color:#f3ea98;background-color:#333}.org-spaceline-python-venv{color:#fbf}.org-speedbar-button{color:#008b00}.org-speedbar-directory{color:#00008b}.org-speedbar-file{color:#008b8b}.org-speedbar-highlight{background-color:#0f0}.org-speedbar-selected{color:red;text-decoration:underline}.org-speedbar-separator{color:#fff;background-color:#00f;text-decoration:overline}.org-speedbar-tag{color:brown}.org-string{color:#8b2252}.org-success{color:#228b22;font-weight:700}.org-table-cell{color:#e5e5e5;background-color:#00f}.org-tex-math{color:#8b2252}.org-tool-bar{color:#000;background-color:#bfbfbf}.org-tooltip{color:#000;background-color:#ffffe0}.org-trailing-whitespace{background-color:red}.org-tty-menu-disabled{color:#d3d3d3;background-color:#00f}.org-tty-menu-enabled{color:#ff0;background-color:#00f;font-weight:700}.org-tty-menu-selected{background-color:red}.org-type{color:#228b22}.org-underline{text-decoration:underline}.org-undo-tree-visualizer-active-branch{color:#000;font-weight:700}.org-undo-tree-visualizer-current{color:red}.org-undo-tree-visualizer-default{color:#bebebe}.org-undo-tree-visualizer-register{color:#ff0}.org-undo-tree-visualizer-unmodified{color:#0ff}.org-variable-name{color:sienna}.org-vhlXdefault{background-color:#ff0}.org-warning{color:#ff8c00;font-weight:700}.org-warning-1{color:red;font-weight:700}.org-wgrep{color:#fff;background-color:#228b22}.org-wgrep-delete{color:pink;background-color:#228b22}.org-wgrep-done{color:#00f}.org-wgrep-file{color:#fff;background-color:#228b22}.org-wgrep-reject{color:red;font-weight:700}.org-which-key-command-description{color:#00f}.org-which-key-docstring{color:#b22222}.org-which-key-group-description{color:#a020f0}.org-which-key-highlighted-command{color:#00f;text-decoration:underline}.org-which-key-key{color:#008b8b}.org-which-key-local-map-description{color:#00f}.org-which-key-note,.org-which-key-separator{color:#b22222}.org-which-key-special-key{color:#008b8b;font-weight:700}.org-whitespace-big-indent{color:#b22222;background-color:red}.org-whitespace-empty{color:#b22222;background-color:#ff0}.org-whitespace-hspace{color:#d3d3d3;background-color:#cdc9a5}.org-whitespace-indentation{color:#b22222;background-color:#ff0}.org-whitespace-line{color:violet;background-color:#333}.org-whitespace-newline{color:#d3d3d3}.org-whitespace-space{color:#d3d3d3;background-color:#ffffe0}.org-whitespace-space-after-tab{color:#b22222;background-color:#ff0}.org-whitespace-space-before-tab{color:#b22222;background-color:#ff8c00}.org-whitespace-tab{color:#d3d3d3;background-color:beige}.org-whitespace-trailing{color:#ff0;background-color:red;font-weight:700}.org-widget-button{font-weight:700}.org-widget-button-pressed{color:red}.org-widget-documentation{color:#006400}.org-widget-field{background-color:#d9d9d9}.org-widget-inactive{color:#7f7f7f}.org-widget-single-line-field{background-color:#d9d9d9}.org-window-divider{color:#999}.org-window-divider-first-pixel{color:#ccc}.org-window-divider-last-pixel{color:#666}a{color:inherit;background-color:inherit;font:inherit;text-decoration:inherit}a:hover{text-decoration:underline}body{width:95%;margin:2% auto;font-size:14px;line-height:1.4em;font-family:Georgia,serif;color:#333}@media screen and (min-width:600px){body{font-size:18px}}@media screen and (min-width:910px){body{width:900px}}::selection{background:#d6edff}p{margin:1em auto}dl,ol,ul{margin:0 auto}.title{text-align:center;margin:.8em auto;color:#000}.subtitle{text-align:center;font-size:1.1em;line-height:1.4;font-weight:700;margin:1em auto}.abstract{margin:auto;width:80%;font-style:italic}.abstract p:last-of-type:before{content:"    ";white-space:pre}.status{font-size:90%;margin:2em auto}[class^=section-number-]{margin-right:.5em}[id^=orgheadline]{clear:both}#footnotes{font-size:90%}.footpara{display:inline;margin:.2em auto}.footdef{margin-bottom:1em}.footdef sup{padding-right:.5em}a{color:#527d9a;text-decoration:none}a:hover{color:#035;border-bottom:1px dotted}figure{padding:0;margin:1em auto;text-align:center}img{max-width:100%;vertical-align:middle}.MathJax_Display{margin:0!important;width:90%!important}h1,h2,h3,h4,h5,h6{color:#a5573e;line-height:1em;font-family:Helvetica,sans-serif}h1,h2,h3{line-height:1.4em}h4,h5,h6{font-size:1em}@media screen and (min-width:600px){h1{font-size:2em}h2{font-size:1.5em}h3{font-size:1.3em}h1,h2,h3{line-height:1.4em}h4,h5,h6{font-size:1.1em}}dt{font-weight:700}table{margin:1em auto;border-top:2px solid;border-bottom:2px solid;border-collapse:collapse}thead{border-bottom:2px solid}table td+td,table th+th{border-left:1px solid grey}table tr{border-top:1px solid #d3d3d3}td,th{padding:.3em .6em;vertical-align:middle}caption.t-above{caption-side:top}caption.t-bottom{caption-side:bottom}caption{margin-bottom:.3em}figcaption{margin-top:.3em}th.org-center,th.org-left,th.org-right{text-align:center}td.org-right{text-align:right}td.org-left{text-align:left}td.org-center{text-align:center}blockquote{margin:1em 2em;padding-left:1em;border-left:3px solid #ccc}kbd{background-color:#f7f7f7;font-size:80%;margin:0 .1em;padding:.1em .6em}.todo{background-color:red;color:#fff;padding:.1em .3em;border-radius:3px;background-clip:padding-box;font-size:80%;font-family:Lucida Console,monospace;line-height:1}.done{background-color:green;color:#fff;padding:.1em .3em;border-radius:3px;background-clip:padding-box;font-size:80%;font-family:Lucida Console,monospace;line-height:1}.priority{color:orange;font-family:Lucida Console,monospace}#table-of-contents li{clear:both}.tag{font-family:Lucida Console,monospace;font-size:.7em;font-weight:400}.tag span{padding:.3em;float:right;margin-right:.5em;border:1px solid #bbb;border-radius:3px;background-clip:padding-box;color:#333;background-color:#eee;line-height:1}.timestamp{color:#bebebe;font-size:90%}.timestamp-kwd{color:#5f9ea0}.org-right{margin-left:auto;margin-right:0;text-align:right}.org-left{margin-left:0;margin-right:auto;text-align:left}.org-center{margin-left:auto;margin-right:auto;text-align:center}.underline{text-decoration:underline}#postamble p,#preamble p{font-size:90%;margin:.2em}p.verse{margin-left:3%}:not(pre)>code{padding:2px 5px;margin:auto 1px;border:1px solid #ddd;border-radius:3px;background-clip:padding-box;color:#333;font-size:80%}.org-src-container{border:1px solid #ccc;box-shadow:3px 3px 3px #eee;font-family:Lucida Console,monospace;font-size:80%;margin:1em auto;padding:.1em .5em;position:relative}.org-src-container>pre{overflow:auto}.org-src-container>pre:before{display:block;position:absolute;background-color:#b3b3b3;top:0;right:0;padding:0 .5em;border-bottom-left-radius:8px;border:0;color:#fff;font-size:80%}.org-src-container>pre.src-sh:before{content:"sh"}.org-src-container>pre.src-bash:before{content:"bash"}.org-src-container>pre.src-emacs-lisp:before{content:"Emacs Lisp"}.org-src-container>pre.src-R:before{content:"R"}.org-src-container>pre.src-cpp:before{content:"C++"}.org-src-container>pre.src-c:before{content:"C"}.org-src-container>pre.src-html:before{content:"HTML"}.org-src-container>pre.src-javascript:before,.org-src-container>pre.src-js:before{content:"Javascript"}// More languages 0% http://orgmode.org/worg/org-contrib/babel/languages.html .org-src-container>pre.src-abc:before{content:"ABC"}.org-src-container>pre.src-asymptote:before{content:"Asymptote"}.org-src-container>pre.src-awk:before{content:"Awk"}.org-src-container>pre.src-C:before{content:"C"}.org-src-container>pre.src-calc:before{content:"Calc"}.org-src-container>pre.src-clojure:before{content:"Clojure"}.org-src-container>pre.src-comint:before{content:"comint"}.org-src-container>pre.src-css:before{content:"CSS"}.org-src-container>pre.src-D:before{content:"D"}.org-src-container>pre.src-ditaa:before{content:"Ditaa"}.org-src-container>pre.src-dot:before{content:"Dot"}.org-src-container>pre.src-ebnf:before{content:"ebnf"}.org-src-container>pre.src-forth:before{content:"Forth"}.org-src-container>pre.src-F90:before{content:"Fortran"}.org-src-container>pre.src-gnuplot:before{content:"Gnuplot"}.org-src-container>pre.src-haskell:before{content:"Haskell"}.org-src-container>pre.src-io:before{content:"Io"}.org-src-container>pre.src-java:before{content:"Java"}.org-src-container>pre.src-latex:before{content:"LaTeX"}.org-src-container>pre.src-ledger:before{content:"Ledger"}.org-src-container>pre.src-ly:before{content:"Lilypond"}.org-src-container>pre.src-lisp:before{content:"Lisp"}.org-src-container>pre.src-makefile:before{content:"Make"}.org-src-container>pre.src-matlab:before{content:"Matlab"}.org-src-container>pre.src-max:before{content:"Maxima"}.org-src-container>pre.src-mscgen:before{content:"Mscgen"}.org-src-container>pre.src-Caml:before{content:"Objective"}.org-src-container>pre.src-octave:before{content:"Octave"}.org-src-container>pre.src-org:before{content:"Org"}.org-src-container>pre.src-perl:before{content:"Perl"}.org-src-container>pre.src-picolisp:before{content:"Picolisp"}.org-src-container>pre.src-plantuml:before{content:"PlantUML"}.org-src-container>pre.src-python:before{content:"Python"}.org-src-container>pre.src-ruby:before{content:"Ruby"}.org-src-container>pre.src-sass:before{content:"Sass"}.org-src-container>pre.src-scala:before{content:"Scala"}.org-src-container>pre.src-scheme:before{content:"Scheme"}.org-src-container>pre.src-screen:before{content:"Screen"}.org-src-container>pre.src-sed:before{content:"Sed"}.org-src-container>pre.src-shell:before{content:"shell"}.org-src-container>pre.src-shen:before{content:"Shen"}.org-src-container>pre.src-sql:before{content:"SQL"}.org-src-container>pre.src-sqlite:before{content:"SQLite"}.org-src-container>pre.src-stan:before{content:"Stan"}.org-src-container>pre.src-vala:before{content:"Vala"}.org-src-container>pre.src-axiom:before{content:"Axiom"}.org-src-container>pre.src-browser:before{content:"HTML"}.org-src-container>pre.src-cypher:before{content:"Neo4j"}.org-src-container>pre.src-elixir:before{content:"Elixir"}.org-src-container>pre.src-request:before{content:"http"}.org-src-container>pre.src-ipython:before{content:"iPython"}.org-src-container>pre.src-kotlin:before{content:"Kotlin"}.org-src-container>pre.src-Flavored Erlang lfe:before{content:"Lisp"}.org-src-container>pre.src-mongo:before{content:"MongoDB"}.org-src-container>pre.src-prolog:before{content:"Prolog"}.org-src-container>pre.src-rec:before{content:"rec"}.org-src-container>pre.src-ML sml:before{content:"Standard"}.org-src-container>pre.src-Translate translate:before{content:"Google"}.org-src-container>pre.src-typescript:before{content:"Typescript"}.org-src-container>pre.src-rust:before{content:"Rust"}.inlinetask{background:#ffc;border:2px solid grey;margin:10px;padding:10px}#org-div-home-and-up{font-size:70%;text-align:right;white-space:nowrap}.linenr{font-size:90%}.code-highlighted{background-color:#ff0}#bibliography{font-size:90%}#bibliography table{width:100%}.creator{display:block}@media screen and (min-width:600px)





@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }

  a,
  a:visited {
    text-decoration: underline;
  }

  a[href]:after {
    content: " (" attr(href) ")";
  }

  abbr[title]:after {
    content: " (" attr(title) ")";
  }

  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }

  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }

  thead {
    display: table-header-group;
  }

  tr,
  img {
    page-break-inside: avoid;
  }

  img {
    max-width: 100% !important;
  }

  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }

  h2,
  h3 {
    page-break-after: avoid;
  }
}

pre,
code {
  font-family: Menlo, Monaco, "Courier New", monospace;
}

pre {
  padding: .5rem;
  line-height: 1.25;
  overflow-x: scroll;
}

a,
a:visited {
  color: #3498db;
}

a:hover,
a:focus,
a:active {
  color: #2980b9;
}

.modest-no-decoration {
  text-decoration: none;
}

html {
  font-size: 12px;
}

@media screen and (min-width: 32rem) and (max-width: 48rem) {
  html {
    font-size: 15px;
  }
}

@media screen and (min-width: 48rem) {
  html {
    font-size: 16px;
  }
}

body {
  line-height: 1.85;
}

p,
.modest-p {
  font-size: 1rem;
  margin-bottom: 1.3rem;
}

h1,
.modest-h1,
h2,
.modest-h2,
h3,
.modest-h3,
h4,
.modest-h4 {
  margin: 1.414rem 0 .5rem;
  font-weight: inherit;
  line-height: 1.42;
}

h1,
.modest-h1 {
  margin-top: 0;
  font-size: 3.998rem;
}

h2,
.modest-h2 {
  font-size: 2.827rem;
}

h3,
.modest-h3 {
  font-size: 1.999rem;
}

h4,
.modest-h4 {
  font-size: 1.414rem;
}

h5,
.modest-h5 {
  font-size: 1.121rem;
}

h6,
.modest-h6 {
  font-size: .88rem;
}

small,
.modest-small {
  font-size: .707em;
}

/* https://github.com/mrmrs/fluidity */

img,
canvas,
iframe,
video,
svg,
select,
textarea {
  max-width: 100%;
}

@import url(http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,300italic,700);

@import url(http://fonts.googleapis.com/css?family=Arimo:700,700italic);

html {
  font-size: 18px;
  max-width: 100%;
}

body {
  color: #444;
  font-family: 'Open Sans Condensed', sans-serif;
  font-weight: 300;
  margin: 0 auto;
  max-width: 48rem;
  line-height: 1.45;
  padding: .25rem;
}

h1,
h2,
h3,
h4,
h5,
h6 {
  font-family: Arimo, Helvetica, sans-serif;
}

h1,
h2,
h3 {
  border-bottom: 2px solid #fafafa;
  margin-bottom: 1.15rem;
  padding-bottom: .5rem;
  text-align: center;
}

blockquote {
  border-left: 8px solid #fafafa;
  padding: 1rem;
}

pre,
code {
  background-color: #fafafa;
}


/;]]>;/-->
</style>

<script type="text/javascript" src="https://orgmode.org/org-info.js">
/**
 *
 * @source: https://orgmode.org/org-info.js
 *
 * @licstart  The following is the entire license notice for the
 *  JavaScript code in https://orgmode.org/org-info.js.
 *
 * Copyright (C) 2012-2019 Free Software Foundation, Inc.
 *
 *
 * The JavaScript code in this tag is free software: you can
 * redistribute it and/or modify it under the terms of the GNU
 * General Public License (GNU GPL) as published by the Free Software
 * Foundation, either version 3 of the License, or (at your option)
 * any later version.  The code is distributed WITHOUT ANY WARRANTY;
 * without even the implied warranty of MERCHANTABILITY or FITNESS
 * FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.
 *
 * As additional permission under GNU GPL version 3 section 7, you
 * may distribute non-source (e.g., minimized or compacted) forms of
 * that code without the copy of the GNU GPL normally required by
 * section 4, provided you include this license notice and a URL
 * through which recipients can access the Corresponding Source.
 *
 * @licend  The above is the entire license notice
 * for the JavaScript code in https://orgmode.org/org-info.js.
 *
 */
</script>

<script type="text/javascript">

/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/

<!--/*--><![CDATA[/*><!--*/
org_html_manager.set("TOC_DEPTH", "3");
org_html_manager.set("LINK_HOME", "");
org_html_manager.set("LINK_UP", "");
org_html_manager.set("LOCAL_TOC", "1");
org_html_manager.set("VIEW_BUTTONS", "0");
org_html_manager.set("MOUSE_HINT", "underline");
org_html_manager.set("FIXED_TOC", "0");
org_html_manager.set("TOC", "3");
org_html_manager.set("VIEW", "info");
org_html_manager.setup();  // activate after the parameters are set
/*]]>*///-->
</script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Intro Data Sci Assignment</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#question-1">1. (1) Linear Regression&#xa0;&#xa0;&#xa0;<span class="tag"><span class="R">R</span>&#xa0;<span class="linear">linear</span>&#xa0;<span class="regression">regression</span></span></a>
<ul>
<li><a href="#explore-the-data-set">1.1. (1) Explore the Data Set</a>
<ul>
<li><a href="#identify-any-linear-relations">1.1.1. Identify any Linear Relations</a></li>
</ul>
</li>
<li><a href="#orgfbb7f8e">1.2. (2) Select the most Suitable Attribute to use for Simple Linear</a>
<ul>
<li><a href="#create-the-model">1.2.1. Create the Model</a></li>
</ul>
</li>
<li><a href="#model-the-performance-using-multiple-linear-regression">1.3. (3) Model the Performance using Multiple Linear Regression</a>
<ul>
<li><a href="#collinearity">1.3.1. Collinearity</a></li>
<li><a href="#linearity">1.3.2. Linearity</a></li>
<li><a href="#feature-interaction">1.3.3. Feature Interaction</a></li>
<li><a href="#fit-the-model">1.3.4. Fit the Model</a></li>
<li><a href="#find-the-best-model">1.3.5. Find the Best Model</a></li>
<li><a href="#consider-interaction-terms">1.3.6. Consider interaction terms</a></li>
</ul>
</li>
<li><a href="#d-model-diagnostics">1.4. (d) Model Diagnostics&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ModelEvaluation">ModelEvaluation</span></span></a>
<ul>
<li><a href="#ggplot2">1.4.1. ggplot2</a></li>
</ul>
</li>
<li><a href="#transform-the-data-to-overcome-diagnostic-issues.">1.5. (5) Transform the data to overcome diagnostic issues.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="transformation">transformation</span></span></a></li>
</ul>
</li>
<li><a href="#question-2">2. (2) Cross Validation&#xa0;&#xa0;&#xa0;<span class="tag"><span class="regression">regression</span></span></a>
<ul>
<li><a href="#choose-an-appropriate-polynomial-attribute">2.1. (1) Choose an appropriate polynomial attribute&#xa0;&#xa0;&#xa0;<span class="tag"><span class="regression">regression</span>&#xa0;<span class="polynomial">polynomial</span></span></a>
<ul>
<li><a href="#consider-cycle-time">2.1.1. Consider Cycle Time</a></li>
<li><a href="#choose-the-best-performing-variable">2.1.2. Choose the best performing variable</a></li>
</ul>
</li>
<li><a href="#use-10-fold-cv-to-select-the-optimal-model">2.2. (2) Use 10-fold CV to Select the Optimal Model&#xa0;&#xa0;&#xa0;<span class="tag"><span class="CrossVal">CrossVal</span></span></a></li>
<li><a href="#comment-on-the-accuracy-of-the-model">2.3. (3) Comment on the Accuracy of the Model&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ModelEvaluation">ModelEvaluation</span></span></a></li>
<li><a href="#model-diagnostics">2.4. (4) Model Diagnostics&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ModelEvaluation">ModelEvaluation</span></span></a></li>
</ul>
</li>
<li><a href="#question-3---wine-trees">3. (3) Classification Trees&#xa0;&#xa0;&#xa0;<span class="tag"><span class="classification">classification</span></span></a>
<ul>
<li><a href="#create-a-test-and-training-set">3.1. (1) Create a test and training set</a></li>
<li><a href="#build-a-decision-tree">3.2. (2) Build a decision tree&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ggplot2">ggplot2</span></span></a>
<ul>
<li><a href="#superior-plot">3.2.1. Superior plot</a></li>
<li><a href="#significant-attributes">3.2.2. Significant Attributes</a></li>
</ul>
</li>
<li><a href="#model-performance">3.3. (3) Model Performance&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ModelEvaluation">ModelEvaluation</span></span></a>
<ul>
<li><a href="#comment-on-the-error">3.3.1. Comment on the Error</a></li>
</ul>
</li>
<li><a href="#build-a-categorical-decision-tree">3.4. (4) Build a categorical decision tree</a></li>
</ul>
</li>
<li><a href="#question-4">4. (4) Support Vector Machines&#xa0;&#xa0;&#xa0;<span class="tag"><span class="svm">svm</span></span></a>
<ul>
<li><a href="#design-a-support-vector-machine">4.1. (1) Design a Support Vector Machine</a>
<ul>
<li><a href="#create-a-categorical-variable">4.1.1. Create a categorical Variable</a></li>
<li><a href="#create-the-svm">4.1.2. Create the SVM</a></li>
<li><a href="#compare-different-types-of-kernels">4.1.3. Compare Different types of kernels</a></li>
</ul>
</li>
<li><a href="#what-is-the-peformance">4.2. What is the peformance?</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org947b5bb" class="outline-2">
<h2 id="question-1"><span class="section-number-2">1</span> (1) Linear Regression&#xa0;&#xa0;&#xa0;<span class="tag"><span class="R">R</span>&#xa0;<span class="linear">linear</span>&#xa0;<span class="regression">regression</span></span></h2>
<div class="outline-text-2" id="text-question-1">
</div>

<div id="outline-container-org44e268a" class="outline-3">
<h3 id="explore-the-data-set"><span class="section-number-3">1.1</span> (1) Explore the Data Set</h3>
<div class="outline-text-3" id="text-explore-the-data-set">
<p>
Explore the given dataset and identify the attributes of CPU that have
linear association with CPU performance.
</p>

<p>
Load and inspect the dataset in R:
</p>

<div class="org-src-container">
<pre class="src src-R">cpu <span style="color: #a45bad;">&lt;-</span> read.csv<span style="color: #4f97d7;">(</span>file = <span style="color: #2d9574;">"./Code/Datasets/CPU.csv"</span>, header = <span style="color: #ce537a; font-weight: bold;">TRUE</span>, sep = <span style="color: #2d9574;">","</span><span style="color: #4f97d7;">)</span>
head<span style="color: #4f97d7;">(</span>cpu<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
##   CycleTime MinimumMainMemory MaximumMainMemory CacheSize
## 1       125               256              6000       256
## 2        29              8000             32000        32
## 3        29              8000             32000        32
## 4        29              8000             32000        32
## 5        29              8000             16000        32
## 6        26              8000             32000        64
##   MinimumNumberOfChannels MaximumNumberOfChannels Performance
## 1                      16                     128         198
## 2                       8                      32         269
## 3                       8                      32         220
## 4                       8                      32         172
## 5                       8                      16         132
## 6                       8                      32         318
</pre>

<div class="org-src-container">
<pre class="src src-R">str<span style="color: #4f97d7;">(</span>cpu<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 'data.frame':    209 obs. of  7 variables:
##  $ CycleTime              : int  125 29 29 29 29 26 23 23 23 23 ...
##  $ MinimumMainMemory      : int  256 8000 8000 8000 8000 8000 16000 16000 16000 32000 ...
##  $ MaximumMainMemory      : int  6000 32000 32000 32000 16000 32000 32000 32000 64000 64000 ...
##  $ CacheSize              : int  256 32 32 32 32 64 64 64 64 128 ...
##  $ MinimumNumberOfChannels: int  16 8 8 8 8 8 16 16 16 32 ...
##  $ MaximumNumberOfChannels: int  128 32 32 32 16 32 32 32 32 64 ...
##  $ Performance            : int  198 269 220 172 132 318 367 489 636 1144 ...
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">dim(cpu)</span>
<span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">summary(cpu)</span>
</pre>
</div>

<p>
From the output it can be seen that this is a data set containing 6
predictive features corresponding to 1 ouput variable with 209
observations.
</p>
</div>

<div id="outline-container-org791527a" class="outline-4">
<h4 id="identify-any-linear-relations"><span class="section-number-4">1.1.1</span> Identify any Linear Relations</h4>
<div class="outline-text-4" id="text-identify-any-linear-relations">
<p>
In order to identify any linear relations <code>corrplot()</code> may be used to
consider the strength and direction of any linear correlation between
variables:
</p>

<div class="org-src-container">
<pre class="src src-R">cpu_pretty <span style="color: #a45bad;">&lt;-</span> cpu
names<span style="color: #4f97d7;">(</span>cpu_pretty<span style="color: #4f97d7;">)</span> <span style="color: #a45bad;">&lt;-</span> c<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Cycle\nPeriod"</span>, <span style="color: #2d9574;">"Min\nMemory"</span>, <span style="color: #2d9574;">"Max\nMemory"</span>, <span style="color: #2d9574;">"Cache"</span>, <span style="color: #2d9574;">"Min\nChannels"</span>, <span style="color: #2d9574;">"Max\nChannels"</span>, <span style="color: #2d9574;">"Performance"</span><span style="color: #4f97d7;">)</span>

corrplot<span style="color: #4f97d7;">(</span>cor<span style="color: #bc6ec5;">(</span>cpu_pretty<span style="color: #bc6ec5;">)</span>,method = <span style="color: #2d9574;">'ellipse'</span>, type = <span style="color: #2d9574;">'upper'</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/corrplot-1.png" alt="corrplot-1.png" />
</p>
<p><span class="figure-number">Figure 1: </span>Correlation Vatrix for CPU Characteristics</p>
</div>

<p>
This suggests that the Maximum Main memory has a strong positive
correlation with performance. In order to further assess the
relationship between performance and maximum main memory a scatter plot
will be drawn in order to investigate the relationships, the <code>pairs()</code>
function is not ideal here because we only need to consider
<i>Performance</i> as a response.
</p>

<p>
It would be possible to call a loop over various plots using the base
packages but it would be more appropriate to create a <i>tidy</i> data frame
and plot multiple facets using <code>ggplot2()</code>:
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">layout(matrix(1:6, nrow = 2))</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">for (i in 1:6) {</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">plot(y=cpu$Performance, x = cpu[,i], xlab = names(cpu)[i], ylab = "Performance")</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">}</span>


  <span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">New facet label names for supp variable</span>
pred.labs <span style="color: #a45bad;">&lt;-</span> c<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Max\nMemory"</span>, <span style="color: #2d9574;">"Min\nMemory"</span><span style="color: #4f97d7;">)</span>
names<span style="color: #4f97d7;">(</span>pred.labs<span style="color: #4f97d7;">)</span> <span style="color: #a45bad;">&lt;-</span> c<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"MaximumMainMemory"</span>, <span style="color: #2d9574;">"MinimumMainMemory"</span><span style="color: #4f97d7;">)</span>


<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Create the plot</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">p + facet_grid(</span>
<span style="color: #2aa1ae; background-color: #292e34;">#   </span><span style="color: #2aa1ae; background-color: #292e34;">dose ~ supp, </span>
<span style="color: #2aa1ae; background-color: #292e34;">#   </span><span style="color: #2aa1ae; background-color: #292e34;">labeller = labeller(dose = dose.labs, supp = supp.labs)</span>
<span style="color: #2aa1ae; background-color: #292e34;">#   </span><span style="color: #2aa1ae; background-color: #292e34;">)</span>

subset <span style="color: #a45bad;">&lt;-</span> names<span style="color: #4f97d7;">(</span>cpu_pretty<span style="color: #4f97d7;">)[</span><span style="color: #a45bad;">2</span>:<span style="color: #a45bad;">3</span><span style="color: #4f97d7;">]</span>
cpu.tidymem <span style="color: #a45bad;">&lt;-</span> pivot_longer<span style="color: #4f97d7;">(</span>data = cpu_pretty<span style="color: #bc6ec5;">[</span>,c<span style="color: #2d9574;">(</span><span style="color: #2d9574;">"Performance"</span>,subset<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">]</span>, cols = subset <span style="color: #4f97d7;">)</span>
pmem <span style="color: #a45bad;">&lt;-</span> ggplot<span style="color: #4f97d7;">(</span>cpu.tidymem, aes<span style="color: #bc6ec5;">(</span>x = value, y = Performance, col = name<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_point<span style="color: #4f97d7;">()</span> + 
  theme_bw<span style="color: #4f97d7;">()</span> +
  geom_smooth<span style="color: #4f97d7;">(</span>method = <span style="color: #2d9574;">'lm'</span><span style="color: #4f97d7;">)</span>+
  facet_grid<span style="color: #4f97d7;">(</span>. ~ name <span style="color: #4f97d7;">)</span> +
  labs<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"CPU \n Characteristic"</span>, x = <span style="color: #ce537a; font-weight: bold;">NULL</span><span style="color: #4f97d7;">)</span>


cpu.else <span style="color: #a45bad;">&lt;-</span> dplyr::select<span style="color: #4f97d7;">(</span>cpu_pretty, -subset<span style="color: #4f97d7;">)</span>
cpu.tidyelse <span style="color: #a45bad;">&lt;-</span> pivot_longer<span style="color: #4f97d7;">(</span>data = cpu.else, cols = <span style="color: #a45bad;">1</span>:<span style="color: #bc6ec5;">(</span>-<span style="color: #a45bad;">1</span>+length<span style="color: #2d9574;">(</span>cpu.else<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
pelse <span style="color: #a45bad;">&lt;-</span> ggplot<span style="color: #4f97d7;">(</span>cpu.tidyelse, aes<span style="color: #bc6ec5;">(</span>x = value, y = Performance, col = name<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_point<span style="color: #4f97d7;">()</span> + 
  theme_bw<span style="color: #4f97d7;">()</span> +
  geom_smooth<span style="color: #4f97d7;">(</span>method = <span style="color: #2d9574;">'lm'</span><span style="color: #4f97d7;">)</span>+
  facet_grid<span style="color: #4f97d7;">(</span>. ~ name, scales = <span style="color: #2d9574;">"free_x"</span><span style="color: #4f97d7;">)</span> + 
  labs<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"CPU \n Characteristic"</span>, x = <span style="color: #ce537a; font-weight: bold;">NULL</span><span style="color: #4f97d7;">)</span>

grid.arrange<span style="color: #4f97d7;">(</span>pmem, pelse, nrow = <span style="color: #a45bad;">2</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/sp-1.png" alt="sp-1.png" />
</p>
<p><span class="figure-number">Figure 2: </span>Scatter Plots of Perfomance given CPU Characteristics</p>
</div>

<p>
All of the variables, with the exception of <code>CycleTime</code>, are linearly
correlated with performance, however the plots demonstrate a violation
with the assumption of homoskedasticity.
</p>
</div>
</div>
</div>

<div id="outline-container-orgfbb7f8e" class="outline-3">
<h3 id="orgfbb7f8e"><span class="section-number-3">1.2</span> (2) Select the most Suitable Attribute to use for Simple Linear</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Regression
</p>
<p>
:CUSTOM<sub>ID</sub>: select-the-most-suitable-attribute-to-use-for-simple-linear-regression
</p>

<p>
Many of the variables are linearly correlated with performance, however,
as mentioned, the plots violate the assumption of homoskedasticity, for
this reason a \(\log\) transform is used.
</p>

<p>
The Cycle period appears to be inversely proportional to performance, it
seems reasonable that cycle frequency will be proportional to
performance and for this reason here a a linear model of cycle frequency
(an inverse transform), will be considered as a potential attribute for
Simple Linear Regression.
</p>

<p>
<code>MaximumMainMemory</code> and <code>MinimimMainMemory</code> are strongly correlated
predictors and so only one of the two should be considered as a
predictive feature. It can be seen from the correlation matrix that
<code>MaximumMainMemory</code> is more strongly correlated with performance and so
it is chosen as the potential predictive feature.
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">layout(matrix(1:6, nrow = 2))</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">for (i in 1:6) {</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">plot(y=cpu$Performance, x = cpu[,i], xlab = names(cpu)[i], ylab = "Performance")</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">}</span>

cpu_pretty$<span style="color: #2d9574;">"ln(Performance)"</span> <span style="color: #a45bad;">&lt;-</span> log<span style="color: #4f97d7;">(</span>cpu_pretty$Performance<span style="color: #4f97d7;">)</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">names(cpu_pretty)[7] &lt;- "ln(Performance)"</span>



subset <span style="color: #a45bad;">&lt;-</span> names<span style="color: #4f97d7;">(</span>cpu_pretty<span style="color: #4f97d7;">)[</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">]</span>
cpu.tidymem <span style="color: #a45bad;">&lt;-</span> pivot_longer<span style="color: #4f97d7;">(</span>data = cpu_pretty<span style="color: #bc6ec5;">[</span>,c<span style="color: #2d9574;">(</span><span style="color: #2d9574;">"ln(Performance)"</span>,subset<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">]</span>, cols = subset <span style="color: #4f97d7;">)</span>
pmem <span style="color: #a45bad;">&lt;-</span> ggplot<span style="color: #4f97d7;">(</span>cpu.tidymem, aes<span style="color: #bc6ec5;">(</span>x = value, y = <span style="color: #b2b2b2; background-color: #292b2e;">`ln(Performance)`</span>, col = name<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_point<span style="color: #4f97d7;">()</span> + 
  theme_bw<span style="color: #4f97d7;">()</span> +
  geom_smooth<span style="color: #4f97d7;">(</span>method = <span style="color: #2d9574;">'lm'</span><span style="color: #4f97d7;">)</span>+
  facet_grid<span style="color: #4f97d7;">(</span>. ~ name <span style="color: #4f97d7;">)</span> +
  labs<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"CPU \n Characteristic"</span>, x = <span style="color: #ce537a; font-weight: bold;">NULL</span><span style="color: #4f97d7;">)</span>


cpu.else <span style="color: #a45bad;">&lt;-</span> dplyr::select<span style="color: #4f97d7;">(</span>cpu_pretty, -subset<span style="color: #4f97d7;">)</span>
cpu.tidyelse <span style="color: #a45bad;">&lt;-</span> pivot_longer<span style="color: #4f97d7;">(</span>data = cpu.else, cols = c<span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">2</span>,<span style="color: #a45bad;">3</span>,<span style="color: #a45bad;">4</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
pelse <span style="color: #a45bad;">&lt;-</span> ggplot<span style="color: #4f97d7;">(</span>cpu.tidyelse, aes<span style="color: #bc6ec5;">(</span>x = value, y = <span style="color: #b2b2b2; background-color: #292b2e;">`ln(Performance)`</span>, col = name<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_point<span style="color: #4f97d7;">()</span> + 
  theme_bw<span style="color: #4f97d7;">()</span> +
  geom_smooth<span style="color: #4f97d7;">(</span>method = <span style="color: #2d9574;">'lm'</span><span style="color: #4f97d7;">)</span>+
  facet_grid<span style="color: #4f97d7;">(</span>. ~ name, scales = <span style="color: #2d9574;">"free_x"</span><span style="color: #4f97d7;">)</span> + 
  labs<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"CPU \n Characteristic"</span>, x = <span style="color: #ce537a; font-weight: bold;">NULL</span><span style="color: #4f97d7;">)</span>

grid.arrange<span style="color: #4f97d7;">(</span>pmem, pelse, nrow = <span style="color: #a45bad;">2</span><span style="color: #4f97d7;">)</span>
</pre>
</div>

<p>
Characteristics
<img src="SecAssignment_files/figure-html/splog-1.png" alt="splog-1.png" />
</p>

<p>
None of these plots are linear despite the transform, it would be
inappropriate to fit a linear model to data that violates the underlying
assumptions of linear regression, instead, consider the cpu frequency:
</p>

<div class="org-src-container">
<pre class="src src-R">cpu_pretty$<span style="color: #2d9574;">"Root Performance"</span> <span style="color: #a45bad;">&lt;-</span> sqrt<span style="color: #4f97d7;">(</span>cpu_pretty$Performance<span style="color: #4f97d7;">)</span>
cpu_pretty$Frequency <span style="color: #a45bad;">&lt;-</span> <span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span>/cpu_pretty$<span style="color: #2d9574;">"Cycle\nPeriod"</span><span style="color: #4f97d7;">)</span>

cpufreq <span style="color: #a45bad;">&lt;-</span> dplyr::select<span style="color: #4f97d7;">(</span>cpu_pretty, c<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Performance"</span>, <span style="color: #2d9574;">"ln(Performance)"</span>, <span style="color: #2d9574;">"Frequency"</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
cpuTidyfreq <span style="color: #a45bad;">&lt;-</span> pivot_longer<span style="color: #4f97d7;">(</span>data = cpufreq, cols = c<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Performance"</span>, <span style="color: #2d9574;">"ln(Performance)"</span><span style="color: #bc6ec5;">)</span>, names_to = <span style="color: #2d9574;">"Performance\nMeasure"</span><span style="color: #4f97d7;">)</span>


ggplot<span style="color: #4f97d7;">(</span>data = cpuTidyfreq, aes<span style="color: #bc6ec5;">(</span>x = Frequency, y = value, col = <span style="color: #b2b2b2; background-color: #292b2e;">`Performance\nMeasure`</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_point<span style="color: #4f97d7;">()</span> +
  theme_bw<span style="color: #4f97d7;">()</span> +
  geom_smooth<span style="color: #4f97d7;">(</span>method = <span style="color: #2d9574;">'lm'</span><span style="color: #4f97d7;">)</span> +
  facet_grid<span style="color: #4f97d7;">(</span><span style="color: #b2b2b2; background-color: #292b2e;">`Performance\nMeasure`</span> ~ ., scales = <span style="color: #2d9574;">"free_y"</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-2-1.png" alt="unnamed-chunk-2-1.png" />
</p>
</div>

<p>
From this it can be seen that the frequency is far more linear than
other variables after a log transform, for this reason frequency is
chosen as the most suitable attribute from which to predict CPU
performance with simple linear regression.
</p>

<p>
Before the log transform it is too heteroskedastic and vialotaes the
assumption of normal residuals, the log transform appears to have
constant variance and appears to be reasonably linear, wheareas other
attributes appear to follow a concave-down and non-linear trend
following the transform.
</p>

<p>
The linear model chosen is of the form:
</p>

<p>
\[
\log{\left( Y_{Perf}\right)} = \beta_0 + \beta_1 \times X_{Freq}
\]
</p>

<p>
this attribute is chosen because it is the only attribute that has a
linear relationship (albeit after a log transform) and the only
attribute that has constant variance from the model.
</p>
</div>

<div id="outline-container-org0a3c1f8" class="outline-4">
<h4 id="create-the-model"><span class="section-number-4">1.2.1</span> Create the Model</h4>
<div class="outline-text-4" id="text-create-the-model">
<p>
The model can be created using the <code>lm</code> function, it is important to not
use <code>I(log(Y))</code> in the model call, otherwise residual plots may not be
generated.
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Training Split</span>
train <span style="color: #a45bad;">&lt;-</span> sample<span style="color: #4f97d7;">(</span>nrow<span style="color: #bc6ec5;">(</span>cpu<span style="color: #bc6ec5;">)</span> * <span style="color: #a45bad;">0.45</span><span style="color: #4f97d7;">)</span>
cpu_mod.slm <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>formula = <span style="color: #b2b2b2; background-color: #292b2e;">`ln(Performance)`</span> ~ Frequency, data = cpu_pretty, subset = train<span style="color: #4f97d7;">)</span>
val.Error <span style="color: #a45bad;">&lt;-</span> <span style="color: #4f97d7;">(</span>cpu_pretty$<span style="color: #b2b2b2; background-color: #292b2e;">`ln(Performance)`</span><span style="color: #bc6ec5;">[</span>-train<span style="color: #bc6ec5;">]</span> - predict<span style="color: #bc6ec5;">(</span>object = cpu_mod.slm, newdata = cpu_pretty<span style="color: #2d9574;">[</span>-train,<span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>^<span style="color: #a45bad;">2</span> <span style="color: #a45bad;">%&gt;%</span>
  mean<span style="color: #4f97d7;">()</span> <span style="color: #a45bad;">%&gt;%</span> 
  sqrt<span style="color: #4f97d7;">()</span> <span style="color: #a45bad;">%&gt;%</span> 
  exp<span style="color: #4f97d7;">()</span> <span style="color: #a45bad;">%&gt;%</span> 
  round<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">3</span><span style="color: #4f97d7;">)</span> <span style="color: #a45bad;">%&gt;%</span> 
  paste<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"is the validation RMSE (expected distance from model"</span><span style="color: #4f97d7;">)</span> <span style="color: #a45bad;">%&gt;%</span> 
  print<span style="color: #4f97d7;">()</span>
</pre>
</div>

<pre class="example">
## [1] "2.249 is the validation RMSE (expected distance from model"
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Return Model</span>
cpu_mod.slm <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span><span style="color: #b2b2b2; background-color: #292b2e;">`ln(Performance)`</span> ~ Frequency, data = cpu_pretty, subset = <span style="color: #ce537a; font-weight: bold;">NULL</span><span style="color: #4f97d7;">)</span>
summary<span style="color: #4f97d7;">(</span>cpu_mod.slm<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 
## Call:
## lm(formula = `ln(Performance)` ~ Frequency, data = cpu_pretty, 
##     subset = NULL)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.20171 -0.43299  0.04276  0.48407  1.80214 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   3.2034     0.0769   41.66   &lt;2e-16 ***
## Frequency    61.2591     4.2183   14.52   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.7396 on 207 degrees of freedom
## Multiple R-squared:  0.5047, Adjusted R-squared:  0.5023 
## F-statistic: 210.9 on 1 and 207 DF,  p-value: &lt; 2.2e-16
</pre>

<p>
Which provides that the specific model, in this case, is:
</p>

<p>
\[
\log_e\left( Y_{Perf}   \right) = 3.2034 + 61.26 \times X_{Freq}
\]
</p>

<p>
The intercept and slope are both highly significant p-values, indicating
that the probability of incorrectly rejecting the null hypothesis, that
there is no linear relationship between frequency and performance
(presuming that the linear assumptions are valid, which they appear to
be), given that the other predictive features are constant, is very low.
</p>

<p>
This model is accpeted because all the coefficients are significant, and
the expected validation error is only 0.8, where as the standard
deviation of the performance variable is 160. The $R$-squared value is
quite poor (a measurement of the proportion of variance explained by the
model), which indicates that there is potentially a better model for the
data.
</p>

<div class="org-src-container">
<pre class="src src-R">sd<span style="color: #4f97d7;">(</span>cpu$Performance<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## [1] 160.8306
</pre>
</div>
</div>
</div>

<div id="outline-container-orgc3492a0" class="outline-3">
<h3 id="model-the-performance-using-multiple-linear-regression"><span class="section-number-3">1.3</span> (3) Model the Performance using Multiple Linear Regression</h3>
<div class="outline-text-3" id="text-model-the-performance-using-multiple-linear-regression">
<p>
From the correlation plot @ref(fig:corrplot) it can be seen that the
following are strongly postively correlated with CPU performance:
</p>

<ul class="org-ul">
<li>Minimum Main Memory</li>
<li>Maximum Main Memory</li>
</ul>

<p>
While the following are weakly correlated with CPU performance.
</p>

<ul class="org-ul">
<li>Cache Size</li>
<li>Minimum Channels</li>
<li>Maximum Channels</li>
</ul>

<p>
Are weakly correlated with CPU performance.
</p>

<p>
<code>Cycletime</code> is very weakly negatively correlated with performance and
may not be useful predictor of performance, however from before it is
clear that frequency is indeed a strongly correlated predictor of
performance and will hence be included in any predictive model.
</p>
</div>

<div id="outline-container-orgd8741d3" class="outline-4">
<h4 id="collinearity"><span class="section-number-4">1.3.1</span> Collinearity</h4>
<div class="outline-text-4" id="text-collinearity">
<p>
The minimum and maximum amount of memory appear to be strongly
positively correlated, indicating that it may be appropriate to consider
only one of those two variables in a model, similar mutlicolinearity is
observed between maximum and minimum channels.
</p>

<p>
In order to assess multi-collinearity the <i>variance inflation factors</i>
(<i>VIF</i>) <sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup> will be calculated for every term of a linear model, a
VIF value that exceeds 5 indicates a problematic amount of collinearity.
</p>
</div>
</div>

<div id="outline-container-org3d02170" class="outline-4">
<h4 id="linearity"><span class="section-number-4">1.3.2</span> Linearity</h4>
<div class="outline-text-4" id="text-linearity">
<p>
Although the <i>Pearson Correlation Coefficient</i> measures the strength of
the linear relationship between variables, the data may have a
non-linear tendency that may compromise the model's capacity to
forecast, this can be seen from the scatter plots at @ref(sp:corrplot),
this could potentially be overcome with a concave transform, such as a
log-transform, this will be considered after fitting the model by
analysing the residuals.
</p>
</div>
</div>

<div id="outline-container-org1e88fd9" class="outline-4">
<h4 id="feature-interaction"><span class="section-number-4">1.3.3</span> Feature Interaction</h4>
<div class="outline-text-4" id="text-feature-interaction">
<p>
A cpu with a higher frequency (i.e. a lower value for <code>CycleTime</code>) may
benefit more significantly from more memory and more channels, hence we
will consider the following interaction terms in a mulitple linear
regression:
</p>

<ul class="org-ul">
<li>Max Memory and Frequency</li>
<li>Max Channels and Frequency</li>
<li>Max Channels, Max Memory and Frequency.</li>
</ul>
</div>
</div>

<div id="outline-container-org644ed0e" class="outline-4">
<h4 id="fit-the-model"><span class="section-number-4">1.3.4</span> Fit the Model</h4>
<div class="outline-text-4" id="text-fit-the-model">
<p>
Backward elimination will be implemented in order to choose the model.
</p>

<div class="org-src-container">
<pre class="src src-R">cpu$Frequency <span style="color: #a45bad;">&lt;-</span> cpu$CycleTime^-<span style="color: #a45bad;">1</span>
cpu_mod.mlm <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>Performance ~ . -CycleTime + I<span style="color: #bc6ec5;">(</span>MaximumNumberOfChannels * MaximumMainMemory * Frequency<span style="color: #bc6ec5;">)</span>  + I<span style="color: #bc6ec5;">(</span>MaximumNumberOfChannels * Frequency<span style="color: #bc6ec5;">)</span> + I<span style="color: #bc6ec5;">(</span> MaximumMainMemory * Frequency<span style="color: #bc6ec5;">)</span>   , data = cpu<span style="color: #4f97d7;">)</span>
summary<span style="color: #4f97d7;">(</span>cpu_mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 
## Call:
## lm(formula = Performance ~ . - CycleTime + I(MaximumNumberOfChannels * 
##     MaximumMainMemory * Frequency) + I(MaximumNumberOfChannels * 
##     Frequency) + I(MaximumMainMemory * Frequency), data = cpu)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -148.536  -12.912   -0.918   12.896  213.929 
## 
## Coefficients:
##                                                              Estimate
## (Intercept)                                                 1.194e+01
## MinimumMainMemory                                           1.327e-02
## MaximumMainMemory                                           1.602e-03
## CacheSize                                                   7.876e-01
## MinimumNumberOfChannels                                     4.696e-01
## MaximumNumberOfChannels                                    -5.654e-01
## Frequency                                                  -1.373e+03
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  9.272e-04
## I(MaximumNumberOfChannels * Frequency)                      7.703e+01
## I(MaximumMainMemory * Frequency)                            3.776e-02
##                                                            Std. Error
## (Intercept)                                                 6.686e+00
## MinimumMainMemory                                           1.521e-03
## MaximumMainMemory                                           6.262e-04
## CacheSize                                                   9.486e-02
## MinimumNumberOfChannels                                     6.948e-01
## MaximumNumberOfChannels                                     2.601e-01
## Frequency                                                   5.747e+02
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  4.511e-04
## I(MaximumNumberOfChannels * Frequency)                      3.428e+01
## I(MaximumMainMemory * Frequency)                            2.657e-02
##                                                            t value
## (Intercept)                                                  1.785
## MinimumMainMemory                                            8.722
## MaximumMainMemory                                            2.559
## CacheSize                                                    8.303
## MinimumNumberOfChannels                                      0.676
## MaximumNumberOfChannels                                     -2.174
## Frequency                                                   -2.389
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)   2.056
## I(MaximumNumberOfChannels * Frequency)                       2.247
## I(MaximumMainMemory * Frequency)                             1.421
##                                                            Pr(&gt;|t|)    
## (Intercept)                                                  0.0757 .  
## MinimumMainMemory                                          1.09e-15 ***
## MaximumMainMemory                                            0.0113 *  
## CacheSize                                                  1.54e-14 ***
## MinimumNumberOfChannels                                      0.5000    
## MaximumNumberOfChannels                                      0.0309 *  
## Frequency                                                    0.0178 *  
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)   0.0411 *  
## I(MaximumNumberOfChannels * Frequency)                       0.0257 *  
## I(MaximumMainMemory * Frequency)                             0.1568    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 38.7 on 199 degrees of freedom
## Multiple R-squared:  0.9446, Adjusted R-squared:  0.9421 
## F-statistic:   377 on 9 and 199 DF,  p-value: &lt; 2.2e-16
</pre>

<p>
The least significant predictor is the variable <code>MinimimMainMemory</code>,
this could be explained by intercorrelation between terms. Before
proceeding the <i>variable inflation factor</i> will be considered, this can
be acheived by using the <code>car::vif()</code> function on a model.
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #a45bad;">library</span><span style="color: #4f97d7;">(</span>car<span style="color: #4f97d7;">)</span>
vif<span style="color: #4f97d7;">(</span>cpu_mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
##                                          MinimumMainMemory 
##                                                   4.836088 
##                                          MaximumMainMemory 
##                                                   7.488001 
##                                                  CacheSize 
##                                                   2.062585 
##                                    MinimumNumberOfChannels 
##                                                   3.115217 
##                                    MaximumNumberOfChannels 
##                                                   6.350779 
##                                                  Frequency 
##                                                   6.779859 
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency) 
##                                                  44.904601 
##                     I(MaximumNumberOfChannels * Frequency) 
##                                                  75.619039 
##                           I(MaximumMainMemory * Frequency) 
##                                                  19.576037
</pre>

<p>
Typically a VIF above 10 indicates a problematic amount of colinearity,
before we may commence with backwards elimination it will be necessary
to remove colinear interaction factors and then consider combining
remaining colinear factors into combined predictor.
</p>

<p>
The Interaction term of channels and frequency has the highest VIF so it
will be removed first:
</p>

<div class="org-src-container">
<pre class="src src-R">cpu_mod.mlm <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>Performance ~ . -CycleTime + I<span style="color: #bc6ec5;">(</span>MaximumNumberOfChannels * MaximumMainMemory * Frequency<span style="color: #bc6ec5;">)</span> + I<span style="color: #bc6ec5;">(</span> MaximumMainMemory * Frequency<span style="color: #bc6ec5;">)</span>   , data = cpu<span style="color: #4f97d7;">)</span> 
vif<span style="color: #4f97d7;">(</span>cpu_mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
##                                          MinimumMainMemory 
##                                                   4.834693 
##                                          MaximumMainMemory 
##                                                   7.295421 
##                                                  CacheSize 
##                                                   1.996105 
##                                    MinimumNumberOfChannels 
##                                                   2.092357 
##                                    MaximumNumberOfChannels 
##                                                   2.865647 
##                                                  Frequency 
##                                                   3.498502 
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency) 
##                                                   4.333099 
##                           I(MaximumMainMemory * Frequency) 
##                                                  19.421320
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">summary(cpu_mod.mlm)</span>
</pre>
</div>

<p>
The interaction term of <code>MaximumMainMemory</code> and <code>Frequency</code> has too high
a <code>VIF()</code> factor, so that will be removed:
</p>

<div class="org-src-container">
<pre class="src src-R">cpu_mod.mlm <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>Performance ~ . -CycleTime + I<span style="color: #bc6ec5;">(</span>MaximumNumberOfChannels * MaximumMainMemory * Frequency<span style="color: #bc6ec5;">)</span>  , data = cpu<span style="color: #4f97d7;">)</span> 
vif<span style="color: #4f97d7;">(</span>cpu_mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
##                                          MinimumMainMemory 
##                                                   3.169999 
##                                          MaximumMainMemory 
##                                                   4.302255 
##                                                  CacheSize 
##                                                   1.897146 
##                                    MinimumNumberOfChannels 
##                                                   2.074288 
##                                    MaximumNumberOfChannels 
##                                                   2.773799 
##                                                  Frequency 
##                                                   2.226321 
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency) 
##                                                   2.931035
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">summary(cpu_mod.mlm)</span>
</pre>
</div>

<p>
The VIF factors are sufficiently low, despite the correlation between
maximum and minimum memory, the sufficiently low VIF values indicate
that there is iinsufficient evidence to remove minimum memory on the
grounds of colinearity and the term will not be removed.
</p>

<p>
A VIF factor of 4 is still somewhat high, however it would be
inappropriate to exclude either variable because having a low minimum
memory is qualitatively different from having a low maximum memory, a
poor configuration of CPU is indicative poor performance and hence the
variables should remain unaltered.
</p>

<div class="org-src-container">
<pre class="src src-R">cpu_mod.mlm <span style="color: #a45bad;">%&gt;%</span> summary<span style="color: #4f97d7;">()</span>
</pre>
</div>

<pre class="example">
## 
## Call:
## lm(formula = Performance ~ . - CycleTime + I(MaximumNumberOfChannels * 
##     MaximumMainMemory * Frequency), data = cpu)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -158.832  -11.365   -1.345   13.350  226.565 
## 
## Coefficients:
##                                                              Estimate
## (Intercept)                                                 1.689e+00
## MinimumMainMemory                                           1.431e-02
## MaximumMainMemory                                           1.862e-03
## CacheSize                                                   8.004e-01
## MinimumNumberOfChannels                                     1.429e+00
## MaximumNumberOfChannels                                    -1.708e-01
## Frequency                                                  -1.693e+02
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  1.988e-03
##                                                            Std. Error
## (Intercept)                                                 4.944e+00
## MinimumMainMemory                                           1.246e-03
## MaximumMainMemory                                           4.800e-04
## CacheSize                                                   9.200e-02
## MinimumNumberOfChannels                                     5.734e-01
## MaximumNumberOfChannels                                     1.738e-01
## Frequency                                                   3.331e+02
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  1.165e-04
##                                                            t value
## (Intercept)                                                  0.342
## MinimumMainMemory                                           11.485
## MaximumMainMemory                                            3.879
## CacheSize                                                    8.700
## MinimumNumberOfChannels                                      2.492
## MaximumNumberOfChannels                                     -0.983
## Frequency                                                   -0.508
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  17.062
##                                                            Pr(&gt;|t|)    
## (Intercept)                                                0.733031    
## MinimumMainMemory                                           &lt; 2e-16 ***
## MaximumMainMemory                                          0.000142 ***
## CacheSize                                                  1.19e-15 ***
## MinimumNumberOfChannels                                    0.013498 *  
## MaximumNumberOfChannels                                    0.326994    
## Frequency                                                  0.611711    
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 39.14 on 201 degrees of freedom
## Multiple R-squared:  0.9428, Adjusted R-squared:  0.9408 
## F-statistic: 473.1 on 7 and 201 DF,  p-value: &lt; 2.2e-16
</pre>

<p>
The term <code>Frequency</code> is not significant and so it will be removed from
the model:
</p>

<div class="org-src-container">
<pre class="src src-R">cpu_mod.mlm <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>Performance ~ . -Frequency -CycleTime + I<span style="color: #bc6ec5;">(</span>MaximumNumberOfChannels * MaximumMainMemory * Frequency<span style="color: #bc6ec5;">)</span>  , data = cpu<span style="color: #4f97d7;">)</span> 
<span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">vif(cpu_mod.mlm)</span>
 summary<span style="color: #4f97d7;">(</span>cpu_mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 
## Call:
## lm(formula = Performance ~ . - Frequency - CycleTime + I(MaximumNumberOfChannels * 
##     MaximumMainMemory * Frequency), data = cpu)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -158.42  -11.51   -1.13   14.02  222.10 
## 
## Coefficients:
##                                                              Estimate
## (Intercept)                                                 0.7551310
## MinimumMainMemory                                           0.0141224
## MaximumMainMemory                                           0.0018003
## CacheSize                                                   0.7946907
## MinimumNumberOfChannels                                     1.3862559
## MaximumNumberOfChannels                                    -0.1589160
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  0.0019897
##                                                            Std. Error
## (Intercept)                                                 4.5817350
## MinimumMainMemory                                           0.0011895
## MaximumMainMemory                                           0.0004635
## CacheSize                                                   0.0911478
## MinimumNumberOfChannels                                     0.5661210
## MaximumNumberOfChannels                                     0.1719460
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  0.0001163
##                                                            t value
## (Intercept)                                                  0.165
## MinimumMainMemory                                           11.873
## MaximumMainMemory                                            3.884
## CacheSize                                                    8.719
## MinimumNumberOfChannels                                      2.449
## MaximumNumberOfChannels                                     -0.924
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  17.109
##                                                            Pr(&gt;|t|)    
## (Intercept)                                                0.869256    
## MinimumMainMemory                                           &lt; 2e-16 ***
## MaximumMainMemory                                          0.000139 ***
## CacheSize                                                  1.03e-15 ***
## MinimumNumberOfChannels                                    0.015190 *  
## MaximumNumberOfChannels                                    0.356474    
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 39.07 on 202 degrees of freedom
## Multiple R-squared:  0.9427, Adjusted R-squared:  0.941 
## F-statistic: 553.9 on 6 and 202 DF,  p-value: &lt; 2.2e-16
</pre>

<p>
The term <code>MaximumNumberOfChannels</code> is not significant and so it will be
removed from the model:
</p>

<div class="org-src-container">
<pre class="src src-R">cpu_mod.mlm <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>Performance ~ . -MaximumNumberOfChannels -Frequency -CycleTime + I<span style="color: #bc6ec5;">(</span>MaximumNumberOfChannels * MaximumMainMemory * Frequency<span style="color: #bc6ec5;">)</span>  , data = cpu<span style="color: #4f97d7;">)</span> 
<span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">vif(cpu_mod.mlm)</span>
 summary<span style="color: #4f97d7;">(</span>cpu_mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 
## Call:
## lm(formula = Performance ~ . - MaximumNumberOfChannels - Frequency - 
##     CycleTime + I(MaximumNumberOfChannels * MaximumMainMemory * 
##     Frequency), data = cpu)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -155.673  -11.509   -0.239   13.303  224.823 
## 
## Coefficients:
##                                                              Estimate
## (Intercept)                                                -7.778e-01
## MinimumMainMemory                                           1.449e-02
## MaximumMainMemory                                           1.770e-03
## CacheSize                                                   7.722e-01
## MinimumNumberOfChannels                                     1.193e+00
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  1.930e-03
##                                                            Std. Error
## (Intercept)                                                 4.269e+00
## MinimumMainMemory                                           1.122e-03
## MaximumMainMemory                                           4.621e-04
## CacheSize                                                   8.782e-02
## MinimumNumberOfChannels                                     5.261e-01
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  9.685e-05
##                                                            t value
## (Intercept)                                                 -0.182
## MinimumMainMemory                                           12.913
## MaximumMainMemory                                            3.829
## CacheSize                                                    8.793
## MinimumNumberOfChannels                                      2.269
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  19.930
##                                                            Pr(&gt;|t|)    
## (Intercept)                                                0.855630    
## MinimumMainMemory                                           &lt; 2e-16 ***
## MaximumMainMemory                                          0.000171 ***
## CacheSize                                                  6.24e-16 ***
## MinimumNumberOfChannels                                    0.024350 *  
## I(MaximumNumberOfChannels * MaximumMainMemory * Frequency)  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 39.05 on 203 degrees of freedom
## Multiple R-squared:  0.9425, Adjusted R-squared:  0.941 
## F-statistic:   665 on 5 and 203 DF,  p-value: &lt; 2.2e-16
</pre>

<p>
All Model terms are now significant so the model is accepted as a
potential model.
</p>
</div>
</div>

<div id="outline-container-org3f62ab2" class="outline-4">
<h4 id="find-the-best-model"><span class="section-number-4">1.3.5</span> Find the Best Model</h4>
<div class="outline-text-4" id="text-find-the-best-model">
<p>
Backward elimination will not necessarily return the optimal model,
instead the method of <i>best subset selection</i> should be used, which
involves choosing the best variables corresponding to a given model size
by way of the training error and then determining the best model size
using an adjusted-measurement of training error, 10-fold
cross-validation could also be used, however there exists the
possibility that no single model performs significantly better and it
would be more appropriate to instead consider using lasso regression,
this is outside the scope of this work and so instead the simplest model
that performs the best with respect to adjusted training error
measurements will be accepted.
</p>
</div>

<ol class="org-ol">
<li><a id="use-the-best-subset-selection"></a>Use the best subset selection<br />
<div class="outline-text-5" id="text-use-the-best-subset-selection">
<div class="org-src-container">
<pre class="src src-R">allMLM <span style="color: #a45bad;">&lt;-</span> regsubsets<span style="color: #4f97d7;">(</span>Performance ~ . -CycleTime, cpu<span style="color: #4f97d7;">)</span>
allMLMSum <span style="color: #a45bad;">&lt;-</span> summary<span style="color: #4f97d7;">(</span>allMLM<span style="color: #4f97d7;">)</span>
</pre>
</div>

<p>
Now take the the AIC, BIC and adjusted R-squared values as an estimate
of the model error
</p>

<div class="org-src-container">
<pre class="src src-R">ErrorCrit <span style="color: #a45bad;">&lt;-</span> tibble<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"preds"</span> = <span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1</span>:<span style="color: #2d9574;">(</span>ncol<span style="color: #67b11d;">(</span>cpu<span style="color: #67b11d;">)</span>-<span style="color: #a45bad;">2</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"adjrsq"</span> = allMLMSum$adjr2, <span style="color: #2d9574;">"bic"</span> = allMLMSum$bic, <span style="color: #2d9574;">"cp"</span>= allMLMSum$cp<span style="color: #4f97d7;">)</span>
ErrorCritSTD <span style="color: #a45bad;">&lt;-</span> ErrorCrit
ErrorCritSTD$adjrsq <span style="color: #a45bad;">&lt;-</span> -<span style="color: #4f97d7;">(</span>ErrorCritSTD$adjrsq-mean<span style="color: #bc6ec5;">(</span>ErrorCritSTD$adjrsq<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>/sd<span style="color: #4f97d7;">(</span>ErrorCritSTD$adjrsq<span style="color: #4f97d7;">)</span>
ErrorCritSTD$bic <span style="color: #a45bad;">&lt;-</span> <span style="color: #4f97d7;">(</span>ErrorCritSTD$bic-mean<span style="color: #bc6ec5;">(</span>ErrorCritSTD$bic<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>/sd<span style="color: #4f97d7;">(</span>ErrorCritSTD$bic<span style="color: #4f97d7;">)</span>
ErrorCritSTD$cp <span style="color: #a45bad;">&lt;-</span> <span style="color: #4f97d7;">(</span>ErrorCritSTD$cp-mean<span style="color: #bc6ec5;">(</span>ErrorCritSTD$cp<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>/sd<span style="color: #4f97d7;">(</span>ErrorCritSTD$cp<span style="color: #4f97d7;">)</span>


allMLMSum$adjr2
</pre>
</div>

<pre class="example">
## [1] 0.7435259 0.7981760 0.8444189 0.8567846 0.8563690 0.8557426
</pre>

<div class="org-src-container">
<pre class="src src-R">ErrorCrit.tidy <span style="color: #a45bad;">&lt;-</span> pivot_longer<span style="color: #4f97d7;">(</span>data = ErrorCrit, cols = c<span style="color: #bc6ec5;">(</span>adjrsq, bic, cp<span style="color: #bc6ec5;">)</span>, names_to = <span style="color: #2d9574;">"adjTrError"</span><span style="color: #4f97d7;">)</span>
ErrorCrit.tidy <span style="color: #a45bad;">&lt;-</span> pivot_longer<span style="color: #4f97d7;">(</span>data = ErrorCritSTD, cols = c<span style="color: #bc6ec5;">(</span>adjrsq, bic, cp<span style="color: #bc6ec5;">)</span>, names_to = <span style="color: #2d9574;">"adjTrError"</span><span style="color: #4f97d7;">)</span>



ErrorCrit.tidy$adjTrError<span style="color: #4f97d7;">[</span>ErrorCrit.tidy$adjTrError==<span style="color: #2d9574;">"adjrsq"</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #2d9574;">"Adjusted R-Squared"</span>
ErrorCrit.tidy$adjTrError<span style="color: #4f97d7;">[</span>ErrorCrit.tidy$adjTrError==<span style="color: #2d9574;">"bic"</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #2d9574;">"BIC"</span>
ErrorCrit.tidy$adjTrError<span style="color: #4f97d7;">[</span>ErrorCrit.tidy$adjTrError==<span style="color: #2d9574;">"cp"</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #2d9574;">"Cp"</span>

ggplot<span style="color: #4f97d7;">(</span>ErrorCrit.tidy, aes<span style="color: #bc6ec5;">(</span>x= preds, y = value, col = adjTrError<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> + 
  geom_point<span style="color: #4f97d7;">(</span>size = <span style="color: #a45bad;">4</span><span style="color: #4f97d7;">)</span> +
  geom_line<span style="color: #4f97d7;">()</span> + 
  labs<span style="color: #4f97d7;">(</span>x = <span style="color: #2d9574;">"Number of Predictors"</span> , y = <span style="color: #2d9574;">"Standardised Training RSS"</span> , col = <span style="color: #2d9574;">"Adjusted Training Error"</span>, title = <span style="color: #2d9574;">"Model Performance Given Parameters"</span><span style="color: #4f97d7;">)</span> +
  theme_classic<span style="color: #4f97d7;">()</span> +
  geom_vline<span style="color: #4f97d7;">(</span>xintercept = which.min<span style="color: #bc6ec5;">(</span>allMLMSum$bic<span style="color: #bc6ec5;">)</span>, col = <span style="color: #2d9574;">"IndianRed"</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-13-1.png" alt="unnamed-chunk-13-1.png" />
</p>
</div>

<p>
This demonstrates that the best performing linear regression is the
model with 4 predictors, the predictors being:
</p>

<div class="org-src-container">
<pre class="src src-R">coef<span style="color: #4f97d7;">(</span>allMLM, <span style="color: #a45bad;">4</span><span style="color: #4f97d7;">)</span> <span style="color: #a45bad;">%&gt;%</span> signif<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
##             (Intercept)       MinimumMainMemory       MaximumMainMemory 
##                -41.0000                  0.0150                  0.0053 
##               CacheSize MaximumNumberOfChannels 
##                  0.5900                  1.4000
</pre>

<p>
and hence the model would be:
</p>

<div class="org-src-container">
<pre class="src src-R">best.Mod.mlm <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>Performance ~ MinimumMainMemory + MaximumMainMemory + CacheSize + MaximumNumberOfChannels, cpu<span style="color: #4f97d7;">)</span>
summary<span style="color: #4f97d7;">(</span>best.Mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 
## Call:
## lm(formula = Performance ~ MinimumMainMemory + MaximumMainMemory + 
##     CacheSize + MaximumNumberOfChannels, data = cpu)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -186.73  -26.08    8.27   26.99  402.87 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             -40.982864   6.041898  -6.783 1.25e-10 ***
## MinimumMainMemory         0.014887   0.001815   8.202 2.61e-14 ***
## MaximumMainMemory         0.005330   0.000645   8.263 1.79e-14 ***
## CacheSize                 0.587097   0.135764   4.324 2.39e-05 ***
## MaximumNumberOfChannels   1.436179   0.210954   6.808 1.08e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 60.86 on 204 degrees of freedom
## Multiple R-squared:  0.8595, Adjusted R-squared:  0.8568 
## F-statistic: 312.1 on 4 and 204 DF,  p-value: &lt; 2.2e-16
</pre>

<p>
\[
Y_{\textsf{Perf}} = -40 + 0.015\times \textsf{MinMem}  + 0.0053 \times \textsf{MaxMem} + 0.59\times \textsf{Cache} + 1.4\times \textsf{MaxChannels}
\]
</p>

<p>
Despite the high performance of frequency for simple linear regression,
suprisingly, it is not a factor in the model, moreover, despite the
anticipated correlation between minimum memory and maximum memory they
are both factors in the best performing model, this is suprising,
however we will next consider interaction between memory and frequency
to see if that is a non-colinear and significant term.
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-org24cc28e" class="outline-4">
<h4 id="consider-interaction-terms"><span class="section-number-4">1.3.6</span> Consider interaction terms</h4>
<div class="outline-text-4" id="text-consider-interaction-terms">
<p>
We may now wish to consider the interactoin term frequency and memory,
as it stands to reason that higher memory may offer more performance for
a cpu that has a higher frequency, moreover the three way interaction
term was significant previously and so an interaction term will by
considered:
</p>

<div class="org-src-container">
<pre class="src src-R">Int.Mod <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>Performance ~ -CycleTime + MinimumMainMemory + MaximumMainMemory + CacheSize + MaximumNumberOfChannels + MaximumMainMemory:Frequency:MaximumNumberOfChannels, data = cpu<span style="color: #4f97d7;">)</span>

<span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">vif(Int.Mod)</span>
newBIC <span style="color: #a45bad;">&lt;-</span> <span style="color: #4f97d7;">(</span>Int.Mod<span style="color: #4f97d7;">)</span> <span style="color: #a45bad;">%&gt;%</span> BIC<span style="color: #4f97d7;">()</span>
origBIC <span style="color: #a45bad;">&lt;-</span> summary<span style="color: #4f97d7;">(</span>regsubsets<span style="color: #bc6ec5;">(</span>Performance ~ . -CycleTime, cpu<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>$bic<span style="color: #4f97d7;">[</span><span style="color: #a45bad;">4</span><span style="color: #4f97d7;">]</span>
</pre>
</div>

<p>
Adding the interaction term increased the adjusted training error from
-383.5184961 to 2161.5715357 and hence this interaction term is rejected
on the grounds that it does not improve the model performance on unseen
data as predicted by the BIC value.
</p>

<p>
Hence the accepted linear model remains unchanged.
</p>
</div>
</div>
</div>

<div id="outline-container-orgb8cea21" class="outline-3">
<h3 id="d-model-diagnostics"><span class="section-number-3">1.4</span> (d) Model Diagnostics&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ModelEvaluation">ModelEvaluation</span></span></h3>
<div class="outline-text-3" id="text-d-model-diagnostics">
<p>
The model should only be accepted if the residuals are normally
distributed, otherwise the error in the model will not be consistent
across the domain of the data, the model diagnostics may be previewed by
using <code>plot()</code> over the model:
</p>

<div class="org-src-container">
<pre class="src src-R">layout<span style="color: #4f97d7;">(</span>matrix<span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1</span>:<span style="color: #a45bad;">4</span>, nrow = <span style="color: #a45bad;">2</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
plot<span style="color: #4f97d7;">(</span>best.Mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-17-1.png" alt="unnamed-chunk-17-1.png" />
</p>
</div>

<p>
These plots are fairly poorly generated and so a better option would be
to use ggplot2.
</p>
</div>

<div id="outline-container-org2a9e25a" class="outline-4">
<h4 id="ggplot2"><span class="section-number-4">1.4.1</span> ggplot2</h4>
<div class="outline-text-4" id="text-ggplot2">
<p>
An implementation for <code>ggplot2()</code> to plot model diagnostics has already
been diagnosed.<sup><a id="fnr.2" class="footref" href="#fn.2">2</a></sup>
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #bc6ec5; font-weight: bold;">diagPlot</span><span style="color: #a45bad;">&lt;-</span><span style="color: #4f97d7; font-weight: bold;">function</span><span style="color: #4f97d7;">(</span>model<span style="color: #4f97d7;">){</span>
    p1<span style="color: #a45bad;">&lt;-</span>ggplot<span style="color: #bc6ec5;">(</span>model, aes<span style="color: #2d9574;">(</span>.fitted, .resid<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>+geom_point<span style="color: #bc6ec5;">(</span>col = <span style="color: #2d9574;">"IndianRed"</span><span style="color: #bc6ec5;">)</span>
    p1<span style="color: #a45bad;">&lt;-</span>p1+stat_smooth<span style="color: #bc6ec5;">(</span>method=<span style="color: #2d9574;">"loess"</span>, col = <span style="color: #2d9574;">"Purple"</span><span style="color: #bc6ec5;">)</span>+geom_hline<span style="color: #bc6ec5;">(</span>yintercept=<span style="color: #a45bad;">0</span>, col=<span style="color: #2d9574;">"red"</span>, linetype=<span style="color: #2d9574;">"dashed"</span><span style="color: #bc6ec5;">)</span>
    p1<span style="color: #a45bad;">&lt;-</span>p1+xlab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Fitted values"</span><span style="color: #bc6ec5;">)</span>+ylab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Residuals"</span><span style="color: #bc6ec5;">)</span>
    p1<span style="color: #a45bad;">&lt;-</span>p1+ggtitle<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Residual vs Fitted Plot"</span><span style="color: #bc6ec5;">)</span>+theme_bw<span style="color: #bc6ec5;">()</span>

    p2<span style="color: #a45bad;">&lt;-</span>ggplot<span style="color: #bc6ec5;">(</span>model, aes<span style="color: #2d9574;">(</span>qqnorm<span style="color: #67b11d;">(</span>.stdresid<span style="color: #67b11d;">)[</span><span style="color: #b1951d;">[</span><span style="color: #a45bad;">1</span><span style="color: #b1951d;">]</span><span style="color: #67b11d;">]</span>, .stdresid<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>+geom_point<span style="color: #bc6ec5;">(</span>col = <span style="color: #2d9574;">"IndianRed"</span>,na.rm = <span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #bc6ec5;">)</span>
    p2<span style="color: #a45bad;">&lt;-</span>p2+geom_abline<span style="color: #bc6ec5;">(</span>slope = <span style="color: #a45bad;">1</span>, intercept = <span style="color: #a45bad;">0</span><span style="color: #bc6ec5;">)</span>+xlab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Theoretical Quantiles"</span><span style="color: #bc6ec5;">)</span>+ylab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Standardized Residuals"</span><span style="color: #bc6ec5;">)</span>
    p2<span style="color: #a45bad;">&lt;-</span>p2+ggtitle<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Normal Q-Q"</span><span style="color: #bc6ec5;">)</span>+theme_bw<span style="color: #bc6ec5;">()</span>

    p3<span style="color: #a45bad;">&lt;-</span>ggplot<span style="color: #bc6ec5;">(</span>model, aes<span style="color: #2d9574;">(</span>.fitted, sqrt<span style="color: #67b11d;">(</span>abs<span style="color: #b1951d;">(</span>.stdresid<span style="color: #b1951d;">)</span><span style="color: #67b11d;">)</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>+geom_point<span style="color: #bc6ec5;">(</span>col = <span style="color: #2d9574;">"IndianRed"</span>,na.rm=<span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #bc6ec5;">)</span>
    p3<span style="color: #a45bad;">&lt;-</span>p3+stat_smooth<span style="color: #bc6ec5;">(</span>method=<span style="color: #2d9574;">"loess"</span>,col = <span style="color: #2d9574;">"Purple"</span> , na.rm = <span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #bc6ec5;">)</span>+xlab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Fitted Value"</span><span style="color: #bc6ec5;">)</span>
    p3<span style="color: #a45bad;">&lt;-</span>p3+ylab<span style="color: #bc6ec5;">(</span>expression<span style="color: #2d9574;">(</span>sqrt<span style="color: #67b11d;">(</span><span style="color: #2d9574;">"|Standardized residuals|"</span><span style="color: #67b11d;">)</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>
    p3<span style="color: #a45bad;">&lt;-</span>p3+ggtitle<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Scale-Location"</span><span style="color: #bc6ec5;">)</span>+theme_bw<span style="color: #bc6ec5;">()</span>

    p4<span style="color: #a45bad;">&lt;-</span>ggplot<span style="color: #bc6ec5;">(</span>model, aes<span style="color: #2d9574;">(</span>seq_along<span style="color: #67b11d;">(</span>.cooksd<span style="color: #67b11d;">)</span>, .cooksd<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>+geom_bar<span style="color: #bc6ec5;">(</span>stat=<span style="color: #2d9574;">"identity"</span>, position=<span style="color: #2d9574;">"identity"</span><span style="color: #bc6ec5;">)</span>
    p4<span style="color: #a45bad;">&lt;-</span>p4+xlab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Obs. Number"</span><span style="color: #bc6ec5;">)</span>+ylab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Cook's distance"</span><span style="color: #bc6ec5;">)</span>
    p4<span style="color: #a45bad;">&lt;-</span>p4+ggtitle<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Cook's distance"</span><span style="color: #bc6ec5;">)</span>+theme_bw<span style="color: #bc6ec5;">()</span>

    p5<span style="color: #a45bad;">&lt;-</span>ggplot<span style="color: #bc6ec5;">(</span>model, aes<span style="color: #2d9574;">(</span>.hat, .stdresid<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>+geom_point<span style="color: #bc6ec5;">(</span>col = <span style="color: #2d9574;">"IndianRed"</span>, aes<span style="color: #2d9574;">(</span>size=.cooksd<span style="color: #2d9574;">)</span>, na.rm=<span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #bc6ec5;">)</span>
    p5<span style="color: #a45bad;">&lt;-</span>p5+stat_smooth<span style="color: #bc6ec5;">(</span>method=<span style="color: #2d9574;">"loess"</span>,col = <span style="color: #2d9574;">"Purple"</span> , na.rm=<span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #bc6ec5;">)</span>
    p5<span style="color: #a45bad;">&lt;-</span>p5+xlab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Leverage"</span><span style="color: #bc6ec5;">)</span>+ylab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Standardized Residuals"</span><span style="color: #bc6ec5;">)</span>
    p5<span style="color: #a45bad;">&lt;-</span>p5+ggtitle<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Residual vs Leverage Plot"</span><span style="color: #bc6ec5;">)</span>
    p5<span style="color: #a45bad;">&lt;-</span>p5+scale_size_continuous<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Cook's Distance"</span>, range=c<span style="color: #2d9574;">(</span><span style="color: #a45bad;">1</span>,<span style="color: #a45bad;">5</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>
    p5<span style="color: #a45bad;">&lt;-</span>p5+theme_bw<span style="color: #bc6ec5;">()</span>+theme<span style="color: #bc6ec5;">(</span>legend.position=<span style="color: #2d9574;">"bottom"</span><span style="color: #bc6ec5;">)</span>

    p6<span style="color: #a45bad;">&lt;-</span>ggplot<span style="color: #bc6ec5;">(</span>model, aes<span style="color: #2d9574;">(</span>.hat, .cooksd<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>+geom_point<span style="color: #bc6ec5;">(</span>col = <span style="color: #2d9574;">"IndianRed"</span>, na.rm=<span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #bc6ec5;">)</span>+stat_smooth<span style="color: #bc6ec5;">(</span>method=<span style="color: #2d9574;">"loess"</span>,col = <span style="color: #2d9574;">"Purple"</span> , na.rm=<span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #bc6ec5;">)</span>
    p6<span style="color: #a45bad;">&lt;-</span>p6+xlab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Leverage hii"</span><span style="color: #bc6ec5;">)</span>+ylab<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Cook's Distance"</span><span style="color: #bc6ec5;">)</span>
    p6<span style="color: #a45bad;">&lt;-</span>p6+ggtitle<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Cook's dist vs Leverage hii/(1-hii)"</span><span style="color: #bc6ec5;">)</span>
    p6<span style="color: #a45bad;">&lt;-</span>p6+geom_abline<span style="color: #bc6ec5;">(</span>slope=<span style="color: #a45bad;">1</span>, intercept = <span style="color: #a45bad;">0</span>, color=<span style="color: #2d9574;">"gray"</span>, linetype=<span style="color: #2d9574;">"dashed"</span><span style="color: #bc6ec5;">)</span>
    p6<span style="color: #a45bad;">&lt;-</span>p6+theme_bw<span style="color: #bc6ec5;">()</span>

    <span style="color: #4f97d7; font-weight: bold;">return</span><span style="color: #bc6ec5;">(</span>list<span style="color: #2d9574;">(</span>rvfPlot=p1, qqPlot=p2, sclLocPlot=p3, cdPlot=p4, rvlevPlot=p5, cvlPlot=p6<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>
<span style="color: #4f97d7;">}</span>
</pre>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #bc6ec5; font-weight: bold;">diagArray</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #4f97d7; font-weight: bold;">function</span><span style="color: #4f97d7;">(</span>model<span style="color: #4f97d7;">){</span>
grid.arrange<span style="color: #bc6ec5;">(</span>
diagPlot<span style="color: #2d9574;">(</span>model<span style="color: #2d9574;">)</span>$rvfPlot,
diagPlot<span style="color: #2d9574;">(</span>model<span style="color: #2d9574;">)</span>$qqPlot,
diagPlot<span style="color: #2d9574;">(</span>model<span style="color: #2d9574;">)</span>$rvlevPlot,
diagPlot<span style="color: #2d9574;">(</span>model<span style="color: #2d9574;">)</span>$cvlPlot<span style="color: #bc6ec5;">)</span>
<span style="color: #4f97d7;">}</span>

diagArray<span style="color: #4f97d7;">(</span>best.Mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-19-1.png" alt="unnamed-chunk-19-1.png" />
</p>
</div>

<p>
The residuals appear somewhat non-normal in the plot of the fitted
values against the model residuals, there appears to be a concave up
pattern in the residuals across the fitted values, the normal QQ plot
appears to deviate significantly from the line and there appears to be
values with high points of leverage.
</p>

<p>
It appears that the assumption of normally distributed residuals may be
violated.
</p>
</div>
</div>
</div>

<div id="outline-container-orgbc1b5b8" class="outline-3">
<h3 id="transform-the-data-to-overcome-diagnostic-issues."><span class="section-number-3">1.5</span> (5) Transform the data to overcome diagnostic issues.&#xa0;&#xa0;&#xa0;<span class="tag"><span class="transformation">transformation</span></span></h3>
<div class="outline-text-3" id="text-transform-the-data-to-overcome-diagnostic-issues.">
<p>
An appropriate transform for the data in order to adress the
non-normality of the residuals would be a concave transform of the
response.
</p>

<div class="org-src-container">
<pre class="src src-R">cpu$rootPerformance <span style="color: #a45bad;">&lt;-</span> sqrt<span style="color: #4f97d7;">(</span>cpu$Performance<span style="color: #4f97d7;">)</span>

hist <span style="color: #a45bad;">&lt;-</span> ggplot<span style="color: #4f97d7;">(</span>cpu, aes<span style="color: #bc6ec5;">(</span>x = Performance<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_histogram<span style="color: #4f97d7;">(</span>binwidth = <span style="color: #a45bad;">80</span><span style="color: #4f97d7;">)</span> +
  theme_classic<span style="color: #4f97d7;">()</span> +
  labs<span style="color: #4f97d7;">(</span>y = <span style="color: #2d9574;">"Observations"</span>, title = <span style="color: #2d9574;">"Histogram of Performance"</span><span style="color: #4f97d7;">)</span>

loghist <span style="color: #a45bad;">&lt;-</span> ggplot<span style="color: #4f97d7;">(</span>cpu, aes<span style="color: #bc6ec5;">(</span>x = rootPerformance<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_histogram<span style="color: #4f97d7;">(</span>binwidth = <span style="color: #a45bad;">1</span><span style="color: #4f97d7;">)</span> +
  theme_classic<span style="color: #4f97d7;">()</span> +
  labs<span style="color: #4f97d7;">(</span>y = <span style="color: #2d9574;">"Observations"</span>, title = <span style="color: #2d9574;">"Histogram of Performance"</span>, x = <span style="color: #2d9574;">"Root-Performance"</span><span style="color: #4f97d7;">)</span>


ggarrange<span style="color: #4f97d7;">(</span>hist, loghist, ncol = <span style="color: #a45bad;">2</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-20-1.png" alt="unnamed-chunk-20-1.png" />
</p>
</div>

<p>
This clearly demonstrates log-normal response data, hence a
log-transform may be appropriate, however a log-transform significantly
compromises the normality of the residuals across the fitted data, and
hence a root-transform is used instead:
</p>

<div class="org-src-container">
<pre class="src src-R">best.Mod.mlm <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>rootPerformance ~ MinimumMainMemory + MaximumMainMemory + CacheSize + MaximumNumberOfChannels, cpu<span style="color: #4f97d7;">)</span>

diagArray<span style="color: #4f97d7;">(</span>best.Mod.mlm<span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-21-1.png" alt="unnamed-chunk-21-1.png" />
</p>
</div>

<p>
The residuals, following the transform, are sufficiently normal in order
to accept the model, although the model appears to have a few points of
high leverage.
</p>

<p>
The optimal multiple linear regression model is hence:
</p>

<p>
\[
Y_{\textsf{Perf}} = -40 + 0.015\times \textsf{MinMem}  + 0.0053 \times \textsf{MaxMem} + 0.59\times \textsf{Cache} + 1.4\times \textsf{MaxChannels}
\]
</p>
</div>
</div>
</div>

<div id="outline-container-org73f2a13" class="outline-2">
<h2 id="question-2"><span class="section-number-2">2</span> (2) Cross Validation&#xa0;&#xa0;&#xa0;<span class="tag"><span class="regression">regression</span></span></h2>
<div class="outline-text-2" id="text-question-2">
</div>

<div id="outline-container-orgb038141" class="outline-3">
<h3 id="choose-an-appropriate-polynomial-attribute"><span class="section-number-3">2.1</span> (1) Choose an appropriate polynomial attribute&#xa0;&#xa0;&#xa0;<span class="tag"><span class="regression">regression</span>&#xa0;<span class="polynomial">polynomial</span></span></h3>
<div class="outline-text-3" id="text-choose-an-appropriate-polynomial-attribute">
<p>
Select the most suitable attribute of CPU that can be used to predict
accurately the performance of CPU using Polynomial Regression.
</p>
</div>

<div id="outline-container-org4fa6fbf" class="outline-4">
<h4 id="consider-cycle-time"><span class="section-number-4">2.1.1</span> Consider Cycle Time</h4>
<div class="outline-text-4" id="text-consider-cycle-time">
<p>
The plot at @ref(fig:sp) shows a very strong non-linear, possibly
directly inversely proprtional, relationship between CycleTime and
performance, for this reason it will be considered as an attribute for a
polynomial model.
</p>

<p>
By the nature of the strong visual relationship between Cycle Time and
performance, it will be considered as a potential attribute to predict
CPU performance using a polynomial model.
</p>

<p>
Create the various models
</p>

<div class="org-src-container">
<pre class="src src-R">set.seed<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">)</span>
maxdeg <span style="color: #a45bad;">&lt;-</span> <span style="color: #a45bad;">15</span>

modsCT <span style="color: #a45bad;">&lt;-</span> vector<span style="color: #4f97d7;">(</span>mode = <span style="color: #2d9574;">"list"</span>, length = maxdeg<span style="color: #4f97d7;">)</span>
modsCT<span style="color: #4f97d7;">[</span><span style="color: #bc6ec5;">[</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> glm<span style="color: #4f97d7;">(</span>Performance ~ I<span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1</span>/CycleTime<span style="color: #bc6ec5;">)</span>, data = cpu<span style="color: #4f97d7;">)</span>
names<span style="color: #4f97d7;">(</span>modsCT<span style="color: #4f97d7;">)[</span><span style="color: #a45bad;">1</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #2d9574;">"Hyperbolic"</span>

<span style="color: #4f97d7; font-weight: bold;">for</span><span style="color: #4f97d7;">(</span>i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #a45bad;">1</span>:maxdeg<span style="color: #4f97d7;">){</span>
modsCT<span style="color: #bc6ec5;">[</span><span style="color: #2d9574;">[</span>i+<span style="color: #a45bad;">1</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">]</span> <span style="color: #a45bad;">&lt;-</span>  glm<span style="color: #bc6ec5;">(</span>Performance ~ poly<span style="color: #2d9574;">(</span>CycleTime, i, raw = <span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #2d9574;">)</span>, data = cpu<span style="color: #bc6ec5;">)</span>
names<span style="color: #bc6ec5;">(</span>modsCT<span style="color: #bc6ec5;">)[</span>i+<span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">]</span> <span style="color: #a45bad;">&lt;-</span> paste<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Degree "</span>, i<span style="color: #bc6ec5;">)</span>
<span style="color: #4f97d7;">}</span>
</pre>
</div>

<p>
Perform cross Validation across the models
</p>

<div class="org-src-container">
<pre class="src src-R">CycTime_CrossValDF <span style="color: #a45bad;">&lt;-</span> tibble<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Model"</span> = factor<span style="color: #bc6ec5;">(</span>names<span style="color: #2d9574;">(</span>modsCT<span style="color: #2d9574;">)</span>, levels = names<span style="color: #2d9574;">(</span>modsCT<span style="color: #2d9574;">)</span>, ordered = <span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"CVError"</span> = rep<span style="color: #bc6ec5;">(</span><span style="color: #ce537a; font-weight: bold;">NA</span>, maxdeg+<span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>


CycTime_CrossValDF<span style="color: #4f97d7;">[</span><span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"CVError"</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> sqrt<span style="color: #4f97d7;">(</span>cv.glm<span style="color: #bc6ec5;">(</span>data = cpu, glmfit = modsCT<span style="color: #2d9574;">[</span><span style="color: #67b11d;">[</span><span style="color: #a45bad;">1</span><span style="color: #67b11d;">]</span><span style="color: #2d9574;">]</span>, K = <span style="color: #a45bad;">10</span><span style="color: #bc6ec5;">)</span>$delta<span style="color: #bc6ec5;">[</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">)</span>
<span style="color: #4f97d7; font-weight: bold;">for</span> <span style="color: #4f97d7;">(</span>i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #a45bad;">1</span>:<span style="color: #bc6ec5;">(</span>maxdeg<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">{</span>
  CycTime_CrossValDF<span style="color: #bc6ec5;">[</span><span style="color: #2d9574;">(</span>i+<span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span>, <span style="color: #2d9574;">"CVError"</span><span style="color: #bc6ec5;">]</span> <span style="color: #a45bad;">&lt;-</span> sqrt<span style="color: #bc6ec5;">(</span>cv.glm<span style="color: #2d9574;">(</span>data = cpu, glmfit = modsCT<span style="color: #67b11d;">[</span><span style="color: #b1951d;">[</span><span style="color: #4f97d7;">(</span>i+<span style="color: #a45bad;">1</span><span style="color: #4f97d7;">)</span><span style="color: #b1951d;">]</span><span style="color: #67b11d;">]</span>, K = <span style="color: #a45bad;">10</span><span style="color: #2d9574;">)</span>$delta<span style="color: #2d9574;">[</span><span style="color: #a45bad;">1</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">)</span>
<span style="color: #4f97d7;">}</span>
</pre>
</div>

<p>
Now plot the CV Error
</p>

<div class="org-src-container">
<pre class="src src-R">ggplot<span style="color: #4f97d7;">(</span>data = CycTime_CrossValDF, aes<span style="color: #bc6ec5;">(</span>x = factor<span style="color: #2d9574;">(</span>Model, ordered = <span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #2d9574;">)</span>, y = CVError, group = <span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_point<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"IndianRed"</span>, size = <span style="color: #a45bad;">5</span><span style="color: #4f97d7;">)</span> +
geom_line<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"Purple"</span><span style="color: #4f97d7;">)</span> +
  theme_classic<span style="color: #4f97d7;">()</span> + 
  labs<span style="color: #4f97d7;">(</span>x = <span style="color: #2d9574;">"Polynomial Model"</span>, y = <span style="color: #2d9574;">"Expected Testing Error"</span>, title = <span style="color: #2d9574;">"Cross Validation for Cycle Time"</span><span style="color: #4f97d7;">)</span> +
  geom_vline<span style="color: #4f97d7;">(</span>xintercept =  <span style="color: #a45bad;">1</span>, col = <span style="color: #2d9574;">"RoyalBlue"</span><span style="color: #4f97d7;">)</span> +
  geom_vline<span style="color: #4f97d7;">(</span>xintercept = which.min<span style="color: #bc6ec5;">(</span>CycTime_CrossValDF<span style="color: #2d9574;">[</span><span style="color: #67b11d;">[</span> <span style="color: #2d9574;">"CVError"</span><span style="color: #67b11d;">]</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">)</span>, col = <span style="color: #2d9574;">"brown"</span><span style="color: #4f97d7;">)</span> +
  theme<span style="color: #4f97d7;">(</span>axis.text.x = element_text<span style="color: #bc6ec5;">(</span>angle = <span style="color: #a45bad;">90</span>, hjust = <span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-24-1.png" alt="unnamed-chunk-24-1.png" />
</p>
</div>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">which.min(CycTime_CrossValDF[[ "CVError"]])</span>
</pre>
</div>

<p>
Although the Cycle Time performs well as a predictive feature within a
polynomial model of a high degree, the simplest model that performs
equallyas well is the hyperbolic model. The simpler model should be
accepted because the higher degree of the model will increase the
variance of the model without significantly improving the performance of
the model. When Cycle time is chosen as the best attribute to model the
performance of the cpu, the hyperbolic model is the optimal model:
</p>

<p>
\[
Y_{Perf} = \frac{8229.468}{X_{CycTime}}
\]
</p>

<p>
However a hyperbola is not a polynomial curve, but a <i>rational</i> curve.
</p>
</div>
</div>

<div id="outline-container-orgef926aa" class="outline-4">
<h4 id="choose-the-best-performing-variable"><span class="section-number-4">2.1.2</span> Choose the best performing variable</h4>
<div class="outline-text-4" id="text-choose-the-best-performing-variable">
<p>
However it may be such that cycle time is not the most appropriate
variable, in order to determine the best single attribute that may be
used to predict performance by way of a polynomialmodel the <i>best
attributes</i> algorithm may be extended:
</p>

<ol class="org-ol">
<li>For all predictors:</li>

<li>Fit all hyperbolic, linear and 2nd to nth degree polynomial models
using only a sinle predictor, choose the predictor that returns the
lowest training error</li>
<li>Repeat for all Predictors</li>

<li>Select a single bestmodel from among the hyperbolic, linear and
polynomial models by using cross validation.</li>
</ol>

<p>
This resulting model will be the best performing model given the
constraints that it must be a polynomial model with only a single
attribute.
</p>
</div>

<ol class="org-ol">
<li><a id="implement-the-algorithm"></a>Implement the Algorithm<br />
<div class="outline-text-5" id="text-implement-the-algorithm">
<p>
Set the seed, create a tibble and create a data frame in which to store
the best predictors:
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Questoin 2 Scratch ------------------------------------------------------</span>
set.seed<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">31415</span><span style="color: #4f97d7;">)</span>


mdg <span style="color: #a45bad;">&lt;-</span> <span style="color: #a45bad;">9</span> <span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Maximum Degree to Consider in Question 2</span>

cpu <span style="color: #a45bad;">&lt;-</span> as_tibble<span style="color: #4f97d7;">(</span>cpu<span style="color: #4f97d7;">)</span>
predictors <span style="color: #a45bad;">&lt;-</span> select<span style="color: #4f97d7;">(</span>cpu, c<span style="color: #bc6ec5;">(</span> <span style="color: #2d9574;">"CycleTime"</span>, <span style="color: #2d9574;">"MinimumMainMemory"</span>, <span style="color: #2d9574;">"MaximumMainMemory"</span>, <span style="color: #2d9574;">"CacheSize"</span>, <span style="color: #2d9574;">"MinimumNumberOfChannels"</span>, <span style="color: #2d9574;">"MaximumNumberOfChannels"</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
names<span style="color: #4f97d7;">(</span>cpu<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## [1] "CycleTime"               "MinimumMainMemory"      
## [3] "MaximumMainMemory"       "CacheSize"              
## [5] "MinimumNumberOfChannels" "MaximumNumberOfChannels"
## [7] "Performance"             "Frequency"              
## [9] "rootPerformance"
</pre>

<div class="org-src-container">
<pre class="src src-R">BestPred <span style="color: #a45bad;">&lt;-</span> data.frame<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Degree"</span> = <span style="color: #a45bad;">1</span>:<span style="color: #bc6ec5;">(</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"BestAttribute"</span> = rep<span style="color: #bc6ec5;">(</span><span style="color: #ce537a; font-weight: bold;">NA</span>, <span style="color: #2d9574;">(</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
</pre>
</div>

<p>
Now create a loop to determine the best attribute for each corresponding
model:
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Lin to 6th deg</span>


BestPred <span style="color: #a45bad;">&lt;-</span> data.frame<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Degree"</span> = <span style="color: #a45bad;">1</span>:<span style="color: #bc6ec5;">(</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"BestAttribute"</span> = rep<span style="color: #bc6ec5;">(</span><span style="color: #ce537a; font-weight: bold;">NA</span>, <span style="color: #2d9574;">(</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>

<span style="color: #4f97d7; font-weight: bold;">for</span> <span style="color: #4f97d7;">(</span>j <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1</span>:mdg<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">{</span>

RSSVals <span style="color: #a45bad;">&lt;-</span> data.frame<span style="color: #bc6ec5;">(</span>names<span style="color: #2d9574;">(</span>predictors<span style="color: #2d9574;">)</span>, <span style="color: #2d9574;">"RSS"</span> = <span style="color: #a45bad;">1</span>:length<span style="color: #2d9574;">(</span>predictors<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>
  <span style="color: #4f97d7; font-weight: bold;">for</span> <span style="color: #bc6ec5;">(</span>i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #a45bad;">1</span>:length<span style="color: #2d9574;">(</span>predictors<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> <span style="color: #bc6ec5;">{</span>

    RSSVals<span style="color: #2d9574;">[</span>i,<span style="color: #a45bad;">2</span><span style="color: #2d9574;">]</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #2d9574;">(</span>glm<span style="color: #67b11d;">(</span>cpu$Performance ~ poly<span style="color: #b1951d;">(</span>as_vector<span style="color: #4f97d7;">(</span>predictors<span style="color: #bc6ec5;">[</span>i<span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">)</span>, j<span style="color: #b1951d;">)</span><span style="color: #67b11d;">)</span>$residuals<span style="color: #2d9574;">)</span>^<span style="color: #a45bad;">2</span> <span style="color: #a45bad;">%&gt;%</span> sum<span style="color: #2d9574;">()</span>

  <span style="color: #bc6ec5;">}</span>

BestPred<span style="color: #bc6ec5;">[</span>j,<span style="color: #a45bad;">2</span><span style="color: #bc6ec5;">]</span> <span style="color: #a45bad;">&lt;-</span>  as.character<span style="color: #bc6ec5;">(</span>RSSVals<span style="color: #2d9574;">[</span>which.min<span style="color: #67b11d;">(</span>RSSVals<span style="color: #b1951d;">[</span>,<span style="color: #a45bad;">2</span><span style="color: #b1951d;">]</span><span style="color: #67b11d;">)</span>,<span style="color: #a45bad;">1</span><span style="color: #2d9574;">][</span><span style="color: #a45bad;">1</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">)</span>
<span style="color: #4f97d7;">}</span>

<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Hyperbolic</span>

RSSVals <span style="color: #a45bad;">&lt;-</span> data.frame<span style="color: #4f97d7;">(</span>names<span style="color: #bc6ec5;">(</span>predictors<span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"RSS"</span> = <span style="color: #a45bad;">1</span>:length<span style="color: #bc6ec5;">(</span>predictors<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
<span style="color: #4f97d7; font-weight: bold;">for</span> <span style="color: #4f97d7;">(</span>i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #a45bad;">1</span>:length<span style="color: #bc6ec5;">(</span>predictors<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">{</span>

  RSSVals<span style="color: #bc6ec5;">[</span>i,<span style="color: #a45bad;">2</span><span style="color: #bc6ec5;">]</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #bc6ec5;">(</span>glm<span style="color: #2d9574;">(</span>cpu$Performance ~ <span style="color: #67b11d;">(</span><span style="color: #a45bad;">1</span>/as_vector<span style="color: #b1951d;">(</span>predictors<span style="color: #4f97d7;">[</span>i<span style="color: #4f97d7;">]</span><span style="color: #b1951d;">)</span><span style="color: #67b11d;">)</span><span style="color: #2d9574;">)</span>$residuals<span style="color: #bc6ec5;">)</span>^<span style="color: #a45bad;">2</span> <span style="color: #a45bad;">%&gt;%</span> sum<span style="color: #bc6ec5;">()</span>

<span style="color: #4f97d7;">}</span>

BestPred$Degree<span style="color: #4f97d7;">[</span><span style="color: #bc6ec5;">(</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> -<span style="color: #a45bad;">1</span>
BestPred<span style="color: #4f97d7;">[</span><span style="color: #bc6ec5;">(</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span>,<span style="color: #a45bad;">2</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span>  as.character<span style="color: #4f97d7;">(</span>RSSVals<span style="color: #bc6ec5;">[</span>which.min<span style="color: #2d9574;">(</span>RSSVals<span style="color: #67b11d;">[</span>,<span style="color: #a45bad;">2</span><span style="color: #67b11d;">]</span><span style="color: #2d9574;">)</span>,<span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">][</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">)</span>

BestPred
</pre>
</div>

<pre class="example">
##    Degree     BestAttribute
## 1       1 MaximumMainMemory
## 2       2 MaximumMainMemory
## 3       3 MaximumMainMemory
## 4       4 MaximumMainMemory
## 5       5 MaximumMainMemory
## 6       6 MaximumMainMemory
## 7       7 MaximumMainMemory
## 8       8 MaximumMainMemory
## 9       9 MaximumMainMemory
## 10     -1         CycleTime
</pre>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-orgbf3f67e" class="outline-3">
<h3 id="use-10-fold-cv-to-select-the-optimal-model"><span class="section-number-3">2.2</span> (2) Use 10-fold CV to Select the Optimal Model&#xa0;&#xa0;&#xa0;<span class="tag"><span class="CrossVal">CrossVal</span></span></h3>
<div class="outline-text-3" id="text-use-10-fold-cv-to-select-the-optimal-model">
<p>
Now that we have the best attribute for any given model, we may use
cross validation in order to decide upon the best model, first however
create a list of models and a data frame in which to store the CV
errors:
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Now I have to perform cross validation on every model</span>
<span style="color: #2aa1ae; background-color: #292e34;">## </span><span style="color: #2aa1ae; background-color: #292e34;">Create a list of models</span>

<span style="color: #2aa1ae; background-color: #292e34;">### </span><span style="color: #2aa1ae; background-color: #292e34;">Create the model names</span>
modnames <span style="color: #a45bad;">&lt;-</span> rep<span style="color: #4f97d7;">(</span><span style="color: #ce537a; font-weight: bold;">NA</span>, <span style="color: #bc6ec5;">(</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
<span style="color: #4f97d7; font-weight: bold;">for</span> <span style="color: #4f97d7;">(</span>i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1</span>:<span style="color: #2d9574;">(</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">{</span>
 modnames<span style="color: #bc6ec5;">[</span>i<span style="color: #bc6ec5;">]</span> <span style="color: #a45bad;">&lt;-</span> paste<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Degree "</span>, i<span style="color: #bc6ec5;">)</span> 

<span style="color: #4f97d7;">}</span>
modnames<span style="color: #4f97d7;">[</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #2d9574;">"Hyperbolic"</span>

<span style="color: #2aa1ae; background-color: #292e34;">### </span><span style="color: #2aa1ae; background-color: #292e34;">Create the list of Models</span>
mods <span style="color: #a45bad;">&lt;-</span> vector<span style="color: #4f97d7;">(</span>mode = <span style="color: #2d9574;">"list"</span>, length = length<span style="color: #bc6ec5;">(</span>modnames<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
names<span style="color: #4f97d7;">(</span>mods<span style="color: #4f97d7;">)</span> <span style="color: #a45bad;">&lt;-</span> modnames

<span style="color: #2aa1ae; background-color: #292e34;">### </span><span style="color: #2aa1ae; background-color: #292e34;">Assign the models</span>

<span style="color: #4f97d7; font-weight: bold;">for</span> <span style="color: #4f97d7;">(</span>i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #a45bad;">1</span>:mdg<span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">{</span>
 mods<span style="color: #bc6ec5;">[</span><span style="color: #2d9574;">[</span>i<span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">]</span> <span style="color: #a45bad;">&lt;-</span>  glm<span style="color: #bc6ec5;">(</span>formula = paste<span style="color: #2d9574;">(</span><span style="color: #2d9574;">"Performance ~ "</span>, BestPred<span style="color: #67b11d;">[</span>i,<span style="color: #a45bad;">2</span><span style="color: #67b11d;">]</span><span style="color: #2d9574;">)</span>, data = cpu<span style="color: #bc6ec5;">)</span>
<span style="color: #4f97d7;">}</span>

mods<span style="color: #4f97d7;">[</span><span style="color: #bc6ec5;">[</span><span style="color: #2d9574;">(</span>mdg+<span style="color: #a45bad;">1</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> glm<span style="color: #4f97d7;">(</span>Performance ~ I<span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1</span>/CycleTime<span style="color: #bc6ec5;">)</span>, data = cpu<span style="color: #4f97d7;">)</span>


<span style="color: #2aa1ae; background-color: #292e34;">## </span><span style="color: #2aa1ae; background-color: #292e34;">Use the list to perform Cross Validation</span>

<span style="color: #2aa1ae; background-color: #292e34;">### </span><span style="color: #2aa1ae; background-color: #292e34;">Make a data frame to track the expected error</span>
BestPred$CVError <span style="color: #a45bad;">&lt;-</span> rep<span style="color: #4f97d7;">(</span><span style="color: #ce537a; font-weight: bold;">NA</span>, nrow<span style="color: #bc6ec5;">(</span>BestPred<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
</pre>
</div>

<p>
Now actually perform the 10-fold cross validation error:
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;">### </span><span style="color: #2aa1ae; background-color: #292e34;">Compute the CV Error</span>
<span style="color: #4f97d7; font-weight: bold;">for</span> <span style="color: #4f97d7;">(</span>r <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #a45bad;">1</span>:nrow<span style="color: #bc6ec5;">(</span>BestPred<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> <span style="color: #4f97d7;">{</span>
BestPred<span style="color: #bc6ec5;">[</span>r,<span style="color: #a45bad;">3</span><span style="color: #bc6ec5;">]</span> <span style="color: #a45bad;">&lt;-</span> sqrt<span style="color: #bc6ec5;">(</span>cv.glm<span style="color: #2d9574;">(</span>data = cpu, glmfit = mods<span style="color: #67b11d;">[</span><span style="color: #b1951d;">[</span>r<span style="color: #b1951d;">]</span><span style="color: #67b11d;">]</span>, K = <span style="color: #a45bad;">10</span><span style="color: #2d9574;">)</span>$delta<span style="color: #2d9574;">[</span><span style="color: #a45bad;">1</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">)</span>
<span style="color: #4f97d7;">}</span>
</pre>
</div>

<p>
Now clean up the names and plot the cross validation Errors:
</p>

<div class="org-src-container">
<pre class="src src-R">BestPred$names <span style="color: #a45bad;">&lt;-</span> names<span style="color: #4f97d7;">(</span>mods<span style="color: #4f97d7;">)</span>
BestPred <span style="color: #a45bad;">&lt;-</span> arrange<span style="color: #4f97d7;">(</span>.data = BestPred, sort.by = Degree<span style="color: #4f97d7;">)</span>
names<span style="color: #4f97d7;">(</span>BestPred<span style="color: #4f97d7;">)[</span><span style="color: #a45bad;">2</span><span style="color: #4f97d7;">]</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #2d9574;">"Best Attribute"</span>


ggplot<span style="color: #4f97d7;">(</span>BestPred, aes<span style="color: #bc6ec5;">(</span>x = factor<span style="color: #2d9574;">(</span>Degree, labels = BestPred$names, ordered = <span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #2d9574;">)</span>, y = CVError, group = <span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> + 
  geom_point<span style="color: #4f97d7;">(</span>aes<span style="color: #bc6ec5;">(</span>shape = <span style="color: #b2b2b2; background-color: #292b2e;">`Best Attribute`</span>, col = <span style="color: #b2b2b2; background-color: #292b2e;">`Best Attribute`</span><span style="color: #bc6ec5;">)</span>,  size = <span style="color: #a45bad;">5</span><span style="color: #4f97d7;">)</span> +
  geom_line<span style="color: #4f97d7;">()</span> +
  theme_classic<span style="color: #4f97d7;">()</span>  +
  labs<span style="color: #4f97d7;">(</span>x = <span style="color: #2d9574;">"Model Type"</span>,
       y = TeX<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Estimated Testing Error $\\pm $ Performance"</span><span style="color: #bc6ec5;">)</span>,
       title = <span style="color: #2d9574;">"Cross Validation of Different Models"</span><span style="color: #4f97d7;">)</span> +
  geom_vline<span style="color: #4f97d7;">(</span>xintercept = which.min<span style="color: #bc6ec5;">(</span>BestPred$CVError<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>+
  theme<span style="color: #4f97d7;">(</span>axis.text.x = element_text<span style="color: #bc6ec5;">(</span>angle = <span style="color: #a45bad;">90</span>, hjust = <span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-29-1.png" alt="unnamed-chunk-29-1.png" />
</p>
</div>

<p>
If leave-one out CV is performed the optimal model will also be found to
be a 3rd degree polynomial, hence the best polynomial model, using only
one attribute, is a 3rd degree polynomial using <code>MaximumMainMemory</code>:
</p>

<div class="org-src-container">
<pre class="src src-R">bestPoly <span style="color: #a45bad;">&lt;-</span> lm<span style="color: #4f97d7;">(</span>Performance ~ poly<span style="color: #bc6ec5;">(</span>MaximumMainMemory, <span style="color: #a45bad;">3</span><span style="color: #bc6ec5;">)</span>, cpu<span style="color: #4f97d7;">)</span>
summary<span style="color: #4f97d7;">(</span>bestPoly<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 
## Call:
## lm(formula = Performance ~ poly(MaximumMainMemory, 3), data = cpu)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -325.93  -22.30   -9.03   10.59  333.19 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                  105.617      4.579  23.067   &lt;2e-16 ***
## poly(MaximumMainMemory, 3)1 2001.742     66.194  30.240   &lt;2e-16 ***
## poly(MaximumMainMemory, 3)2  684.557     66.194  10.342   &lt;2e-16 ***
## poly(MaximumMainMemory, 3)3  -79.978     66.194  -1.208    0.228    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 66.19 on 205 degrees of freedom
## Multiple R-squared:  0.833,  Adjusted R-squared:  0.8306 
## F-statistic:   341 on 3 and 205 DF,  p-value: &lt; 2.2e-16
</pre>

<p>
so the model is:
</p>

<p>
\[
Y_{Perf} = 106 + 2002 \times \textsf{Mem} + 685 \times \textsf{Mem}^2 -80 \times \textsf{Mem}^3
\]
</p>
</div>
</div>

<div id="outline-container-orgf04630e" class="outline-3">
<h3 id="comment-on-the-accuracy-of-the-model"><span class="section-number-3">2.3</span> (3) Comment on the Accuracy of the Model&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ModelEvaluation">ModelEvaluation</span></span></h3>
<div class="outline-text-3" id="text-comment-on-the-accuracy-of-the-model">
<p>
The expected RMSE of the model on unseen data is approximately 82.5 as
determined by 10-fold Cross Validation, so it would be expected that
this model will make predictions with an expected error of 82.5, this is
significantly less than the standard deviation of the CPU performance
and so the model would be expected to perform significantly better than
mere chance.
</p>
</div>
</div>

<div id="outline-container-org1dfad75" class="outline-3">
<h3 id="model-diagnostics"><span class="section-number-3">2.4</span> (4) Model Diagnostics&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ModelEvaluation">ModelEvaluation</span></span></h3>
<div class="outline-text-3" id="text-model-diagnostics">
<p>
The residuals of the best performing model may be considered thusly:
</p>

<div class="org-src-container">
<pre class="src src-R">diagArray<span style="color: #4f97d7;">(</span>bestPoly<span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-31-1.png" alt="unnamed-chunk-31-1.png" />
</p>
</div>

<p>
The residuals appear to be bunched up to the left, however there is no
clear pattern in them, although they do not necessarily look normally
distributed, the normal q-q plot has a wave to it and so the
distribution of the residuals would hence correspond to a 'fat-tailed'
distribution.
</p>

<p>
The residual plots are not sufficiently non-normal to reject the model
on grounds of non-normal residuals. Hence the attribute
<code>MaximumMainMemory</code> is accepted as the most suitable attribute for the
most optimal single variable polynomial regression, as measured by
10-fold Cross Validation.
</p>
</div>
</div>
</div>

<div id="outline-container-org57435a2" class="outline-2">
<h2 id="question-3---wine-trees"><span class="section-number-2">3</span> (3) Classification Trees&#xa0;&#xa0;&#xa0;<span class="tag"><span class="classification">classification</span></span></h2>
<div class="outline-text-2" id="text-question-3---wine-trees">
</div>

<div id="outline-container-org2f36c2c" class="outline-3">
<h3 id="create-a-test-and-training-set"><span class="section-number-3">3.1</span> (1) Create a test and training set</h3>
<div class="outline-text-3" id="text-create-a-test-and-training-set">
<p>
Divide the dataset into Training set with 4000 observations and assign
rest of the observations into Test set. [Use set.seed as 10 to generate
same randomness.]
</p>

<p>
The data set may be imported and a training set indexed thusly:
</p>

<div class="org-src-container">
<pre class="src src-R">set.seed<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">10</span><span style="color: #4f97d7;">)</span>

<span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">Import the data</span>
wine <span style="color: #a45bad;">&lt;-</span> as_tibble<span style="color: #4f97d7;">(</span>read.csv<span style="color: #bc6ec5;">(</span>file = <span style="color: #2d9574;">"./Code/Datasets/Wine.csv"</span>, header = <span style="color: #ce537a; font-weight: bold;">TRUE</span>, sep = <span style="color: #2d9574;">","</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
glimpse<span style="color: #4f97d7;">(</span>wine<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## Observations: 4,898
## Variables: 12
## $ WineQuality        &lt;int&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 7, 5, …
## $ FixedAcidity       &lt;dbl&gt; 7.0, 6.3, 8.1, 7.2, 7.2, 8.1, 6.2, 7.0, 6.3, …
## $ VolatileAcidity    &lt;dbl&gt; 0.27, 0.30, 0.28, 0.23, 0.23, 0.28, 0.32, 0.2…
## $ CitricAcid         &lt;dbl&gt; 0.36, 0.34, 0.40, 0.32, 0.32, 0.40, 0.16, 0.3…
## $ ResidualSugar      &lt;dbl&gt; 20.70, 1.60, 6.90, 8.50, 8.50, 6.90, 7.00, 20…
## $ Chlorides          &lt;dbl&gt; 0.045, 0.049, 0.050, 0.058, 0.058, 0.050, 0.0…
## $ FreeSulfurDioxide  &lt;dbl&gt; 45, 14, 30, 47, 47, 30, 30, 45, 14, 28, 11, 1…
## $ TotalSulfurDioxide &lt;dbl&gt; 170, 132, 97, 186, 186, 97, 136, 170, 132, 12…
## $ Density            &lt;dbl&gt; 1.0010, 0.9940, 0.9951, 0.9956, 0.9956, 0.995…
## $ PH                 &lt;dbl&gt; 3.00, 3.30, 3.26, 3.19, 3.19, 3.26, 3.18, 3.0…
## $ Sulphates          &lt;dbl&gt; 0.45, 0.49, 0.44, 0.40, 0.40, 0.44, 0.47, 0.4…
## $ Alcohol            &lt;dbl&gt; 8.8, 9.5, 10.1, 9.9, 9.9, 10.1, 9.6, 8.8, 9.5…
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Create a training set</span>
train <span style="color: #a45bad;">&lt;-</span> sample<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">1</span>:<span style="color: #bc6ec5;">(</span>nrow<span style="color: #2d9574;">(</span>wine<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>, size = <span style="color: #a45bad;">4000</span><span style="color: #4f97d7;">)</span>
wine.test  <span style="color: #a45bad;">&lt;-</span> slice<span style="color: #4f97d7;">(</span>wine, -train<span style="color: #4f97d7;">)</span>
wine.train <span style="color: #a45bad;">&lt;-</span> slice<span style="color: #4f97d7;">(</span>wine, train<span style="color: #4f97d7;">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org0020e45" class="outline-3">
<h3 id="build-a-decision-tree"><span class="section-number-3">3.2</span> (2) Build a decision tree&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ggplot2">ggplot2</span></span></h3>
<div class="outline-text-3" id="text-build-a-decision-tree">
<p>
A decision tree may be constructed by using the following code:
</p>

<div class="org-src-container">
<pre class="src src-R">wine.tree <span style="color: #a45bad;">&lt;-</span> tree<span style="color: #4f97d7;">(</span>WineQuality ~ ., wine.train<span style="color: #4f97d7;">)</span>
summary<span style="color: #4f97d7;">(</span>wine.tree<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 
## Regression tree:
## tree(formula = WineQuality ~ ., data = wine.train)
## Variables actually used in tree construction:
## [1] "Alcohol"           "VolatileAcidity"   "FreeSulfurDioxide"
## Number of terminal nodes:  5 
## Residual mean deviance:  0.5788 = 2312 / 3995 
## Distribution of residuals:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -3.5890 -0.3856  0.1013  0.0000  0.6144  3.6140
</pre>

<div class="org-src-container">
<pre class="src src-R">paste<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"SD of Quality: "</span>, sd<span style="color: #bc6ec5;">(</span>wine$WineQuality<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## [1] "SD of Quality:  0.885638574967831"
</pre>

<div class="org-src-container">
<pre class="src src-R">paste<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Average Wine Quality: "</span>, mean<span style="color: #bc6ec5;">(</span>wine$WineQuality<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## [1] "Average Wine Quality:  5.87790935075541"
</pre>

<p>
reducing the number of terminal nodes (known as 'pruning' the tree) may
elicit better performance from the model, this ideal number of terminal
nodes may be considered by using cross validation:
</p>

<div class="org-src-container">
<pre class="src src-R">wine.treeCV <span style="color: #a45bad;">&lt;-</span> cv.tree<span style="color: #4f97d7;">(</span>wine.tree<span style="color: #4f97d7;">)</span>

WineCVError <span style="color: #a45bad;">&lt;-</span> tibble<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Nodes"</span> = wine.treeCV$size, <span style="color: #2d9574;">"RSS"</span> = wine.treeCV$dev, <span style="color: #2d9574;">"MSE"</span> = <span style="color: #bc6ec5;">(</span>wine.treeCV$dev<span style="color: #bc6ec5;">)</span>/length<span style="color: #bc6ec5;">(</span>train<span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"RMSE"</span> = sqrt<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">(</span>wine.treeCV$dev<span style="color: #2d9574;">)</span>/length<span style="color: #2d9574;">(</span>train<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>

ggplot<span style="color: #4f97d7;">(</span>WineCVError, aes<span style="color: #bc6ec5;">(</span>x = Nodes, y = RMSE, group = <span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_point<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"#B223F5"</span>, size = <span style="color: #a45bad;">5</span><span style="color: #4f97d7;">)</span> +
  geom_line<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"#DBA0D6"</span><span style="color: #4f97d7;">)</span> +
  theme_classic2<span style="color: #4f97d7;">()</span> +
  labs<span style="color: #4f97d7;">(</span>title = <span style="color: #2d9574;">"Cross Validation Error"</span>, y = TeX<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Expected Error $ \\left(E ( \\epsilon) \\right)$"</span><span style="color: #bc6ec5;">)</span>, caption = <span style="color: #2d9574;">"RMSE is an estimation of the mean residual value, hence it is expressed that RMSE is the expected model error"</span><span style="color: #4f97d7;">)</span> +
  geom_vline<span style="color: #4f97d7;">(</span>xintercept = as.integer<span style="color: #bc6ec5;">(</span>summary<span style="color: #2d9574;">(</span>wine.treeCV<span style="color: #2d9574;">)[</span><span style="color: #a45bad;">1</span>,<span style="color: #a45bad;">1</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">)</span>, col = c<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"#AB0FFF"</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_hline<span style="color: #4f97d7;">(</span>yintercept = min<span style="color: #bc6ec5;">(</span>WineCVError$RMSE<span style="color: #bc6ec5;">)</span>, col = c<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"#AB0FFF"</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  annotate<span style="color: #4f97d7;">(</span>geom = <span style="color: #2d9574;">"text"</span>, y = <span style="color: #bc6ec5;">(</span>min<span style="color: #2d9574;">(</span>WineCVError$RMSE<span style="color: #2d9574;">)</span>+sd<span style="color: #2d9574;">(</span>WineCVError$RMSE<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>, x = <span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">4</span><span style="color: #bc6ec5;">)</span>, label = paste<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"SD of Error: "</span>, signif<span style="color: #2d9574;">(</span>min<span style="color: #67b11d;">(</span>WineCVError$RMSE<span style="color: #67b11d;">)</span>, <span style="color: #a45bad;">3</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> 
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-34-1.png" alt="unnamed-chunk-34-1.png" />
</p>
</div>

<p>
This suggests that the model initially used, with 5 nodes, is the best
performing model, hence a 5-node tree model is accepted:
</p>

<div class="org-src-container">
<pre class="src src-R">plot<span style="color: #4f97d7;">(</span>wine.tree<span style="color: #4f97d7;">)</span>
text<span style="color: #4f97d7;">(</span>wine.tree, pretty = <span style="color: #a45bad;">1</span>, cex = <span style="color: #a45bad;">0.75</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-35-1.png" alt="unnamed-chunk-35-1.png" />
</p>
</div>
</div>

<div id="outline-container-orgc7ca5e7" class="outline-4">
<h4 id="superior-plot"><span class="section-number-4">3.2.1</span> Superior plot</h4>
<div class="outline-text-4" id="text-superior-plot">
<p>
A superior plot (and automatic cross-validation) may be produced by
using the <code>rpart()</code> function:
</p>

<div class="org-src-container">
<pre class="src src-R">WineModTree.rpart <span style="color: #a45bad;">&lt;-</span> rpart<span style="color: #4f97d7;">(</span>formula = WineQuality~ ., data = wine.train<span style="color: #4f97d7;">)</span>
WineModTree.plot  <span style="color: #a45bad;">&lt;-</span> rpart.plot<span style="color: #4f97d7;">(</span>WineModTree.rpart, box.palette=<span style="color: #2d9574;">"OrGy"</span>, shadow.col=<span style="color: #2d9574;">"gray"</span>, nn=<span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/tree-1.png" alt="tree-1.png" />
</p>
<p><span class="figure-number">Figure 14: </span>Tree Model for Wine Quality</p>
</div>
</div>
</div>

<div id="outline-container-orgfbab177" class="outline-4">
<h4 id="significant-attributes"><span class="section-number-4">3.2.2</span> Significant Attributes</h4>
<div class="outline-text-4" id="text-significant-attributes">
<p>
It can be oveserved from @ref(fig: tree) that in creating this model
only the measurements of acohol, volatile acidity and free sulfur
dioxide are found to be significant, the mean square error (MSE) of this
model (errounesly listed as deviance by this package) is 0.58, which is
a reasonably low training error, given that this is significantly lower
than the standard deviation of the wine quality which is 0.89 with an
average wine quality value of 5.9.
</p>
</div>
</div>
</div>

<div id="outline-container-org38bb2b7" class="outline-3">
<h3 id="model-performance"><span class="section-number-3">3.3</span> (3) Model Performance&#xa0;&#xa0;&#xa0;<span class="tag"><span class="ModelEvaluation">ModelEvaluation</span></span></h3>
<div class="outline-text-3" id="text-model-performance">
</div>

<ol class="org-ol">
<li><a id="comparison-to-testing-data"></a>Comparison to testing data<br />
<div class="outline-text-5" id="text-comparison-to-testing-data">
<div class="org-src-container">
<pre class="src src-R">wineTreePreds.test <span style="color: #a45bad;">&lt;-</span> predict<span style="color: #4f97d7;">(</span>object = wine.tree, newdata = wine.test<span style="color: #4f97d7;">)</span>

<span style="color: #bc6ec5; font-weight: bold;">rmse</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #4f97d7; font-weight: bold;">function</span><span style="color: #4f97d7;">(</span>pred, obs<span style="color: #4f97d7;">){</span>
  <span style="color: #4f97d7; font-weight: bold;">if</span><span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">require</span><span style="color: #2d9574;">(</span><span style="color: #2d9574;">"tidyverse"</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">){</span>
    <span style="color: #2d9574;">(</span>pred-obs<span style="color: #2d9574;">)</span>^<span style="color: #a45bad;">2</span> <span style="color: #a45bad;">%&gt;%</span> mean <span style="color: #a45bad;">%&gt;%</span> sqrt<span style="color: #2d9574;">()</span>
  <span style="color: #bc6ec5;">}</span> <span style="color: #4f97d7; font-weight: bold;">else</span><span style="color: #bc6ec5;">{</span>
    print<span style="color: #2d9574;">(</span><span style="color: #2d9574;">"Install Tidyverse first"</span><span style="color: #2d9574;">)</span>
  <span style="color: #bc6ec5;">}</span>
<span style="color: #4f97d7;">}</span>

wineTree.rmse <span style="color: #a45bad;">&lt;-</span> rmse<span style="color: #4f97d7;">(</span>pred = wineTreePreds.test, obs = wine.test$WineQuality<span style="color: #4f97d7;">)</span>
</pre>
</div>
</div>
</li>
</ol>

<div id="outline-container-orgab695cf" class="outline-4">
<h4 id="comment-on-the-error"><span class="section-number-4">3.3.1</span> Comment on the Error</h4>
<div class="outline-text-4" id="text-comment-on-the-error">
<p>
Cross validation provides that the expected error by using this model is
0.77 units of quality, the same expected error value is returned from
fitting the model to testing data, the standard deviation (i.e. the
expected difference between values of wine quality) is about 0.89, so
this model is expected, by cross validation, to perform better than mere
chance.
</p>
</div>
</div>
</div>

<div id="outline-container-orgf579eb0" class="outline-3">
<h3 id="build-a-categorical-decision-tree"><span class="section-number-3">3.4</span> (4) Build a categorical decision tree</h3>
<div class="outline-text-3" id="text-build-a-categorical-decision-tree">
<p>
First create a factor of variables for high and low wine quality
</p>

<div class="org-src-container">
<pre class="src src-R">wine$WineCat <span style="color: #a45bad;">&lt;-</span> ifelse<span style="color: #4f97d7;">(</span>wine$WineQuality &gt; <span style="color: #a45bad;">6</span>, <span style="color: #2d9574;">"high"</span>, <span style="color: #2d9574;">"low"</span><span style="color: #4f97d7;">)</span>
wine$WineCat <span style="color: #a45bad;">&lt;-</span> factor<span style="color: #4f97d7;">(</span>x = wine$WineCat, levels = c<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"low"</span>, <span style="color: #2d9574;">"high"</span><span style="color: #bc6ec5;">)</span>, ordered = <span style="color: #ce537a; font-weight: bold;">TRUE</span>, nmax = <span style="color: #a45bad;">2</span><span style="color: #4f97d7;">)</span>

wine.test  <span style="color: #a45bad;">&lt;-</span> slice<span style="color: #4f97d7;">(</span>wine, -train<span style="color: #4f97d7;">)</span>
wine.train <span style="color: #a45bad;">&lt;-</span> slice<span style="color: #4f97d7;">(</span>wine, train<span style="color: #4f97d7;">)</span>
</pre>
</div>

<p>
the tree model may be constructed thusly:
</p>

<div class="org-src-container">
<pre class="src src-R">wineCat.tree <span style="color: #a45bad;">&lt;-</span> tree<span style="color: #4f97d7;">(</span>WineCat ~ . -WineQuality, wine.train<span style="color: #4f97d7;">)</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">plot(wineCat.tree)</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">text(wineCat.tree, pretty = 1, cex = 0.75)</span>
</pre>
</div>

<p>
A better performing model may be found by 'pruning' the tree, showing
preference for a model that reduces the misclassification rate for cross
validation (as opposed to cost complexity pruning):
</p>

<div class="org-src-container">
<pre class="src src-R">wineCat.treeCV <span style="color: #a45bad;">&lt;-</span> cv.tree<span style="color: #4f97d7;">(</span>object = wineCat.tree, FUN = prune.misclass, K = <span style="color: #a45bad;">10</span><span style="color: #4f97d7;">)</span>

wineCat.treeCV
</pre>
</div>

<pre class="example">
## $size
## [1] 6 5 3 1
## 
## $dev
## [1] 835 835 837 857
## 
## $k
## [1] -Inf  0.0  3.5 10.5
## 
## $method
## [1] "misclass"
## 
## attr(,"class")
## [1] "prune"         "tree.sequence"
</pre>

<div class="org-src-container">
<pre class="src src-R">summary<span style="color: #4f97d7;">(</span>wineCat.tree<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 
## Classification tree:
## tree(formula = WineCat ~ . - WineQuality, data = wine.train)
## Variables actually used in tree construction:
## [1] "Alcohol"         "VolatileAcidity"
## Number of terminal nodes:  6 
## Residual mean deviance:  0.8307 = 3318 / 3994 
## Misclassification error rate: 0.2065 = 826 / 4000
</pre>

<div class="org-src-container">
<pre class="src src-R">WineCatCVError <span style="color: #a45bad;">&lt;-</span> tibble<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Nodes"</span> = as.numeric<span style="color: #bc6ec5;">(</span>wineCat.treeCV$size<span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"MisClas"</span> = wineCat.treeCV$dev/length<span style="color: #bc6ec5;">(</span>train<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
WineCatCVError <span style="color: #a45bad;">&lt;-</span> arrange<span style="color: #4f97d7;">(</span>WineCatCVError, Nodes<span style="color: #4f97d7;">)</span>

WineCatCVError <span style="color: #a45bad;">&lt;-</span> tibble<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Nodes"</span> = factor<span style="color: #bc6ec5;">(</span>x = WineCatCVError<span style="color: #2d9574;">[</span><span style="color: #67b11d;">[</span> <span style="color: #2d9574;">"Nodes"</span><span style="color: #67b11d;">]</span><span style="color: #2d9574;">]</span>, levels = WineCatCVError<span style="color: #2d9574;">[</span><span style="color: #67b11d;">[</span> <span style="color: #2d9574;">"Nodes"</span><span style="color: #67b11d;">]</span><span style="color: #2d9574;">]</span>, ordered = <span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"MisClas"</span> = WineCatCVError<span style="color: #bc6ec5;">[</span><span style="color: #2d9574;">[</span> <span style="color: #2d9574;">"MisClas"</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">)</span>
bestNode <span style="color: #a45bad;">&lt;-</span> WineCatCVError<span style="color: #4f97d7;">[</span><span style="color: #bc6ec5;">[</span> <span style="color: #2d9574;">"Nodes"</span><span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">][</span>which.min<span style="color: #bc6ec5;">(</span>WineCatCVError<span style="color: #2d9574;">[</span><span style="color: #67b11d;">[</span><span style="color: #2d9574;">"MisClas"</span><span style="color: #67b11d;">]</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">]</span>
bestMisclas <span style="color: #a45bad;">&lt;-</span> WineCatCVError<span style="color: #4f97d7;">[</span><span style="color: #bc6ec5;">[</span> <span style="color: #2d9574;">"MisClas"</span><span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">][</span>bestNode<span style="color: #4f97d7;">]</span>

ggplot<span style="color: #4f97d7;">(</span>WineCatCVError, aes<span style="color: #bc6ec5;">(</span>x = Nodes, y = MisClas, group = <span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_point<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"#B223F5"</span>, size = <span style="color: #a45bad;">5</span><span style="color: #4f97d7;">)</span> +
  geom_line<span style="color: #4f97d7;">(</span>col = <span style="color: #2d9574;">"#DBA0D6"</span><span style="color: #4f97d7;">)</span> +
  theme_classic2<span style="color: #4f97d7;">()</span> +
  labs<span style="color: #4f97d7;">(</span>title = <span style="color: #2d9574;">"Cross Validation Error"</span>, y = <span style="color: #2d9574;">"Misclassificatoin Rate"</span>, caption = <span style="color: #2d9574;">"Misclassification Rate is a measurement of the expected frequency of misclassification as determined by Cross Validation"</span><span style="color: #4f97d7;">)</span> +
  geom_vline<span style="color: #4f97d7;">(</span>xintercept = as.integer<span style="color: #bc6ec5;">(</span>bestNode<span style="color: #bc6ec5;">)</span>, col = c<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"#AB0FFF"</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_hline<span style="color: #4f97d7;">(</span>yintercept = bestMisclas, col = c<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"#AB0FFF"</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  annotate<span style="color: #4f97d7;">(</span>geom = <span style="color: #2d9574;">"text"</span>, y = bestMisclas+sd<span style="color: #bc6ec5;">(</span>WineCatCVError$MisClas<span style="color: #bc6ec5;">)</span>, x = <span style="color: #bc6ec5;">(</span><span style="color: #a45bad;">1.1</span>+<span style="color: #a45bad;">3</span><span style="color: #bc6ec5;">)</span>, label = paste<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Misclassification Rate: \n"</span>, signif<span style="color: #2d9574;">(</span>min<span style="color: #67b11d;">(</span>WineCatCVError$MisClas<span style="color: #67b11d;">)</span>, <span style="color: #a45bad;">3</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> 
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-40-1.png" alt="unnamed-chunk-40-1.png" />
</p>
</div>

<p>
The expected misclassification rate on unseen data for this model, as
predicted by Cross Validatoin, will be minised by choosing five nodes
and hence the model will be pruned from six to five terminal nodes, this
can be acheived by using the <code>prune.misclass()</code> function:
</p>

<div class="org-src-container">
<pre class="src src-R">wineCat.tree.prune <span style="color: #a45bad;">&lt;-</span> prune.misclass<span style="color: #4f97d7;">(</span>wineCat.tree, best = bestNode<span style="color: #4f97d7;">)</span>
plot<span style="color: #4f97d7;">(</span>wineCat.tree.prune<span style="color: #4f97d7;">)</span>
text<span style="color: #4f97d7;">(</span>wineCat.tree.prune, pretty = <span style="color: #a45bad;">1</span>, cex = <span style="color: #a45bad;">0.75</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-41-1.png" alt="unnamed-chunk-41-1.png" />
</p>
</div>
</div>

<ol class="org-ol">
<li><a id="comment-on-the-performance-of-the-model"></a>(5) Comment on the performance of the model<br />
<div class="outline-text-6" id="text-comment-on-the-performance-of-the-model">
<p>
the model can used to on the testing data in order to assess the rate of
misclassification:
</p>

<div class="org-src-container">
<pre class="src src-R">WineTreeCatPreds <span style="color: #a45bad;">&lt;-</span> predict<span style="color: #4f97d7;">(</span>object = wineCat.tree.prune, newdata = wine.test, type = <span style="color: #2d9574;">"class"</span><span style="color: #4f97d7;">)</span>
WineTestObs <span style="color: #a45bad;">&lt;-</span> wine.test$WineCat


<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Now create the confusion Matrix</span>
  <span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">This package prevents making mistakes</span>
  conf.mat <span style="color: #a45bad;">&lt;-</span>   caret::confusionMatrix<span style="color: #4f97d7;">(</span>data = WineTreeCatPreds, reference = WineTestObs<span style="color: #4f97d7;">)</span>
  conf.mat
</pre>
</div>

<pre class="example">
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction low high
##       low  591  107
##       high 101   99
##                                           
##                Accuracy : 0.7684          
##                  95% CI : (0.7394, 0.7956)
##     No Information Rate : 0.7706          
##     P-Value [Acc &gt; NIR] : 0.5813          
##                                           
##                   Kappa : 0.3381          
##                                           
##  Mcnemar's Test P-Value : 0.7288          
##                                           
##             Sensitivity : 0.8540          
##             Specificity : 0.4806          
##          Pos Pred Value : 0.8467          
##          Neg Pred Value : 0.4950          
##              Prevalence : 0.7706          
##          Detection Rate : 0.6581          
##    Detection Prevalence : 0.7773          
##       Balanced Accuracy : 0.6673          
##                                           
##        'Positive' Class : low             
## 
</pre>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">This could otherwise be created by using, always go prediction, reference as a standard</span>
mis.mat <span style="color: #a45bad;">&lt;-</span> table<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"prediction"</span> = WineTreeCatPreds, <span style="color: #2d9574;">"reference"</span> = WineTestObs<span style="color: #4f97d7;">)</span>
  mcr <span style="color: #a45bad;">&lt;-</span> signif<span style="color: #4f97d7;">(</span><span style="color: #bc6ec5;">(</span>mis.mat<span style="color: #2d9574;">[</span><span style="color: #a45bad;">1</span>,<span style="color: #a45bad;">2</span><span style="color: #2d9574;">]</span>+mis.mat<span style="color: #2d9574;">[</span><span style="color: #a45bad;">2</span>,<span style="color: #a45bad;">1</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">)</span>/sum<span style="color: #bc6ec5;">(</span>mis.mat<span style="color: #bc6ec5;">)</span>,<span style="color: #a45bad;">2</span><span style="color: #4f97d7;">)</span>
  mcr
</pre>
</div>

<pre class="example">
## [1] 0.23
</pre>

<p>
The misclassification error rate on the testing data is 23%, this is
comparable with what was predicted via cross validation which returned
20.65%, this misclassification rate corresponds to a tree model trained
to minimise the cross validation misclassification rate (as opposed to
cost-complexity).
</p>

<p>
This misclassification rate is quite high, however for the trade off of
interpretability, this is still an acceptable model. It's very
interesting that a good wine is essenitally synonymous with a strong
wine.
</p>
</div>
</li>
</ol>
</div>
</div>

<div id="outline-container-orgd20d33f" class="outline-2">
<h2 id="question-4"><span class="section-number-2">4</span> (4) Support Vector Machines&#xa0;&#xa0;&#xa0;<span class="tag"><span class="svm">svm</span></span></h2>
<div class="outline-text-2" id="text-question-4">
</div>

<div id="outline-container-org3f8df5f" class="outline-3">
<h3 id="design-a-support-vector-machine"><span class="section-number-3">4.1</span> (1) Design a Support Vector Machine</h3>
<div class="outline-text-3" id="text-design-a-support-vector-machine">
</div>

<div id="outline-container-org97193b7" class="outline-4">
<h4 id="create-a-categorical-variable"><span class="section-number-4">4.1.1</span> Create a categorical Variable</h4>
<div class="outline-text-4" id="text-create-a-categorical-variable">
<p>
Classify CPU performance as an ordered factor with levels of <code>high</code> and
<code>low</code>:
</p>

<div class="org-src-container">
<pre class="src src-R">cpu <span style="color: #a45bad;">&lt;-</span> select<span style="color: #4f97d7;">(</span>cpu, -rootPerformance, -Frequency<span style="color: #4f97d7;">)</span>
cpu$Performance <span style="color: #a45bad;">&lt;-</span> if_else<span style="color: #4f97d7;">(</span>cpu$Performance &gt; <span style="color: #a45bad;">500</span>, <span style="color: #2d9574;">"high"</span>, <span style="color: #2d9574;">"low"</span><span style="color: #4f97d7;">)</span>
cpu$Performance <span style="color: #a45bad;">&lt;-</span> factor<span style="color: #4f97d7;">(</span>cpu$Performance, c<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"low"</span>, <span style="color: #2d9574;">"high"</span><span style="color: #bc6ec5;">)</span>, ordered = <span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #4f97d7;">)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org597a75f" class="outline-4">
<h4 id="create-the-svm"><span class="section-number-4">4.1.2</span> Create the SVM</h4>
<div class="outline-text-4" id="text-create-the-svm">
</div>

<ol class="org-ol">
<li><a id="support-vector-classifier"></a>Support Vector Classifier<br />
<div class="outline-text-5" id="text-support-vector-classifier">
<p>
A support Vector Classifier can be constructed with a linear kernel by
using the <code>svm</code> function:
</p>

<div class="org-src-container">
<pre class="src src-R">set.seed<span style="color: #4f97d7;">(</span><span style="color: #a45bad;">3</span><span style="color: #4f97d7;">)</span>
cpu.svm <span style="color: #a45bad;">&lt;-</span> svm<span style="color: #4f97d7;">(</span>Performance ~ ., data = cpu, kernel = <span style="color: #2d9574;">"linear"</span>, cost = <span style="color: #a45bad;">10</span>, scale = <span style="color: #ce537a; font-weight: bold;">FALSE</span><span style="color: #4f97d7;">)</span>
</pre>
</div>

<p>
Cross validation can used in order to determine the best cost value via
the <code>e1071::tune()</code> function, the cost is, to a degree, a measure of
model flexibility and so there will be an optimal cost value, for
non-linear kernel's differeng gamma values may be considered as well and
hence they will be included in a function call:
</p>

<div class="org-src-container">
<pre class="src src-R"><span style="color: #bc6ec5; font-weight: bold;">makeSVM</span> <span style="color: #a45bad;">&lt;-</span> <span style="color: #4f97d7; font-weight: bold;">function</span><span style="color: #4f97d7;">(</span>formula = Performance ~ ., data = cpu, kernel = <span style="color: #2d9574;">"linear"</span>, plotQ = <span style="color: #ce537a; font-weight: bold;">TRUE</span><span style="color: #4f97d7;">){</span>
<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">cpu.svm &lt;- svm(Performance ~ ., data = cpu, kernel = "linear", cost = 10, scale = FALSE)</span>

tune.cpu <span style="color: #a45bad;">&lt;-</span> tune<span style="color: #bc6ec5;">(</span>method = svm, train.x = formula, data = data, kernel = kernel, ranges = list<span style="color: #2d9574;">(</span>cost = seq<span style="color: #67b11d;">(</span>from = <span style="color: #a45bad;">0.0001</span>, to = <span style="color: #a45bad;">10</span>, length.out = <span style="color: #a45bad;">50</span><span style="color: #67b11d;">)</span><span style="color: #2d9574;">)</span>, gamma = c<span style="color: #2d9574;">(</span><span style="color: #a45bad;">0.5</span>, <span style="color: #a45bad;">1</span>, <span style="color: #a45bad;">2</span>, <span style="color: #a45bad;">3</span>, <span style="color: #a45bad;">4</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>
summary<span style="color: #bc6ec5;">(</span>tune.cpu<span style="color: #bc6ec5;">)</span>
CVErrors <span style="color: #a45bad;">&lt;-</span> as_tibble<span style="color: #bc6ec5;">(</span>summary<span style="color: #2d9574;">(</span>tune.cpu<span style="color: #2d9574;">)[</span><span style="color: #67b11d;">[</span><span style="color: #a45bad;">7</span><span style="color: #67b11d;">]</span><span style="color: #2d9574;">]</span><span style="color: #bc6ec5;">)</span>
CVErrors$error <span style="color: #a45bad;">&lt;-</span> <span style="color: #bc6ec5;">(</span>CVErrors$error<span style="color: #bc6ec5;">)</span>

bestcost <span style="color: #a45bad;">&lt;-</span> CVErrors$cost<span style="color: #bc6ec5;">[</span>CVErrors$error&lt;=min<span style="color: #2d9574;">(</span>CVErrors<span style="color: #67b11d;">[</span><span style="color: #b1951d;">[</span> <span style="color: #2d9574;">"error"</span><span style="color: #b1951d;">]</span><span style="color: #67b11d;">]</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">][</span><span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">]</span>

tuneplot <span style="color: #a45bad;">&lt;-</span> ggplot<span style="color: #bc6ec5;">(</span>CVErrors, aes<span style="color: #2d9574;">(</span>x = cost, y = error<span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> +
  geom_point<span style="color: #bc6ec5;">(</span>col = <span style="color: #2d9574;">"#B223F5"</span>, size = <span style="color: #a45bad;">1</span><span style="color: #bc6ec5;">)</span> +
  geom_line<span style="color: #bc6ec5;">(</span>col = <span style="color: #2d9574;">"#DBA0D6"</span><span style="color: #bc6ec5;">)</span> +
  theme_classic2<span style="color: #bc6ec5;">()</span> +
  labs<span style="color: #bc6ec5;">(</span>title = <span style="color: #2d9574;">"Cross Validation estimation of Error given Cost Parameter"</span>, y = <span style="color: #2d9574;">"Error"</span>, x = <span style="color: #2d9574;">"Cost"</span>, caption = paste<span style="color: #2d9574;">(</span><span style="color: #2d9574;">"The optimal cost parameter appears to occur at a cost value of"</span>, signif<span style="color: #67b11d;">(</span>bestcost, <span style="color: #a45bad;">2</span><span style="color: #67b11d;">)</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> +
  geom_hline<span style="color: #bc6ec5;">(</span>yintercept = <span style="color: #2d9574;">(</span>as.numeric<span style="color: #67b11d;">(</span>summary<span style="color: #b1951d;">(</span>tune.cpu<span style="color: #b1951d;">)[</span><span style="color: #a45bad;">2</span><span style="color: #b1951d;">]</span><span style="color: #67b11d;">)</span><span style="color: #2d9574;">)</span>, col = c<span style="color: #2d9574;">(</span><span style="color: #2d9574;">"#AB0FFF"</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span> + 
  geom_vline<span style="color: #bc6ec5;">(</span>xintercept = bestcost, col = c<span style="color: #2d9574;">(</span><span style="color: #2d9574;">"#AB0FFF"</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span>



<span style="color: #4f97d7; font-weight: bold;">if</span> <span style="color: #bc6ec5;">(</span>plotQ<span style="color: #bc6ec5;">)</span> <span style="color: #bc6ec5;">{</span>
 <span style="color: #4f97d7; font-weight: bold;">return</span><span style="color: #2d9574;">(</span>tuneplot<span style="color: #2d9574;">)</span> 
<span style="color: #bc6ec5;">}</span> <span style="color: #4f97d7; font-weight: bold;">else</span> <span style="color: #bc6ec5;">{</span>
  <span style="color: #4f97d7; font-weight: bold;">return</span><span style="color: #2d9574;">(</span>c<span style="color: #67b11d;">(</span><span style="color: #2d9574;">"ErrorRate"</span> = <span style="color: #b1951d;">(</span>as.numeric<span style="color: #4f97d7;">(</span>summary<span style="color: #bc6ec5;">(</span>tune.cpu<span style="color: #bc6ec5;">)[</span><span style="color: #a45bad;">2</span><span style="color: #bc6ec5;">]</span><span style="color: #4f97d7;">)</span><span style="color: #b1951d;">)</span><span style="color: #67b11d;">)</span><span style="color: #2d9574;">)</span>
<span style="color: #bc6ec5;">}</span>


<span style="color: #4f97d7;">}</span>

<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Consider using `kernlab::ksvm()`</span>

makeSVM<span style="color: #4f97d7;">()</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-45-1.png" alt="unnamed-chunk-45-1.png" />
</p>
</div>

<p>
Using Cross Validation it may be determined that the best cost value for
a linear kernel is 0.21.
</p>
</div>
</li>
</ol>
</div>

<div id="outline-container-org411ee63" class="outline-4">
<h4 id="compare-different-types-of-kernels"><span class="section-number-4">4.1.3</span> Compare Different types of kernels</h4>
<div class="outline-text-4" id="text-compare-different-types-of-kernels">
<p>
In order to compare the performance of the different type of SVM
kernel's a loop can be constructed and the expected testing error, as
determined by cross validation, may be compared:
</p>

<div class="org-src-container">
<pre class="src src-R">models <span style="color: #a45bad;">&lt;-</span> list<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"linear"</span>, <span style="color: #2d9574;">"polynomial"</span>, <span style="color: #2d9574;">"radial"</span>, <span style="color: #2d9574;">"sigmoid"</span><span style="color: #4f97d7;">)</span>
KerDF <span style="color: #a45bad;">&lt;-</span> tibble<span style="color: #4f97d7;">(</span><span style="color: #2d9574;">"Kernel"</span> = c<span style="color: #bc6ec5;">(</span><span style="color: #2d9574;">"Linear"</span>, <span style="color: #2d9574;">"Polynomial"</span>, <span style="color: #2d9574;">"Radial"</span>, <span style="color: #2d9574;">"Sigmoid"</span><span style="color: #bc6ec5;">)</span>, <span style="color: #2d9574;">"CVError"</span> = rep<span style="color: #bc6ec5;">(</span><span style="color: #ce537a; font-weight: bold;">NA</span>, <span style="color: #a45bad;">4</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>


i <span style="color: #a45bad;">&lt;-</span> <span style="color: #a45bad;">1</span>
<span style="color: #4f97d7; font-weight: bold;">for</span> <span style="color: #4f97d7;">(</span>mod <span style="color: #4f97d7; font-weight: bold;">in</span> models<span style="color: #4f97d7;">){</span>
KerDF<span style="color: #bc6ec5;">[</span>i, <span style="color: #a45bad;">2</span><span style="color: #bc6ec5;">]</span> <span style="color: #a45bad;">&lt;-</span> makeSVM<span style="color: #bc6ec5;">(</span>kernel = mod, plotQ = <span style="color: #ce537a; font-weight: bold;">FALSE</span><span style="color: #bc6ec5;">)</span>
i <span style="color: #a45bad;">&lt;-</span> i+<span style="color: #a45bad;">1</span> 
<span style="color: #4f97d7;">}</span>

<span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">KerDF</span>

ggplot<span style="color: #4f97d7;">(</span>KerDF, aes<span style="color: #bc6ec5;">(</span>x = Kernel, y = CVError, fill = Kernel<span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span> +
  geom_col<span style="color: #4f97d7;">(</span>alpha = <span style="color: #a45bad;">0.5</span><span style="color: #4f97d7;">)</span> + 
  theme_bw<span style="color: #4f97d7;">()</span> +
  labs<span style="color: #4f97d7;">(</span>x = <span style="color: #2d9574;">"Kernel Model"</span>, y = <span style="color: #2d9574;">"Expected Misclassification Rate"</span>, title = <span style="color: #2d9574;">"Cross Validated Errors for SVM Models"</span><span style="color: #4f97d7;">)</span>
</pre>
</div>


<div class="figure">
<p><img src="SecAssignment_files/figure-html/unnamed-chunk-46-1.png" alt="unnamed-chunk-46-1.png" />
</p>
</div>

<p>
The linear Model appears to have the lowest expected training error as
determined by 10-fold cross validation, hence the linear SVM model is
accepted as the optimal SVM model with a cost parameter of 0.21:
</p>

<div class="org-src-container">
<pre class="src src-R">cpu.svm <span style="color: #a45bad;">&lt;-</span> svm<span style="color: #4f97d7;">(</span>Performance ~ ., data = cpu, kernel = <span style="color: #2d9574;">"linear"</span>, cost = <span style="color: #a45bad;">10</span>, scale = <span style="color: #ce537a; font-weight: bold;">FALSE</span><span style="color: #4f97d7;">)</span>

tune.cpu <span style="color: #a45bad;">&lt;-</span> tune<span style="color: #4f97d7;">(</span>method = svm, train.x = Performance ~ ., data = cpu, kernel = <span style="color: #2d9574;">"linear"</span>, ranges = list<span style="color: #bc6ec5;">(</span>cost = seq<span style="color: #2d9574;">(</span>from = <span style="color: #a45bad;">0.0001</span>, to = <span style="color: #a45bad;">2</span>, length.out = <span style="color: #a45bad;">30</span><span style="color: #2d9574;">)</span><span style="color: #bc6ec5;">)</span><span style="color: #4f97d7;">)</span>
<span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">summary(tune.cpu)</span>

summary<span style="color: #4f97d7;">(</span>tune.cpu$best.model<span style="color: #4f97d7;">)</span>
</pre>
</div>

<pre class="example">
## 
## Call:
## best.tune(method = svm, train.x = Performance ~ ., data = cpu, 
##     ranges = list(cost = seq(from = 1e-04, to = 2, length.out = 30)), 
##     kernel = "linear")
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  0.2069862 
## 
## Number of Support Vectors:  7
## 
##  ( 3 4 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  low high
</pre>

<p>
The ### Optimal SVM
</p>

<p>
because the <code>svm()</code> function works for more than linear kernels, it is
not simple to return the coefficients of a linear decision
boundary <sup><a id="fnr.3" class="footref" href="#fn.3">3</a></sup>, in order to have this returned there is some more work.
</p>
</div>
</div>
</div>

<div id="outline-container-orgdb19230" class="outline-3">
<h3 id="what-is-the-peformance"><span class="section-number-3">4.2</span> What is the peformance?</h3>
<div class="outline-text-3" id="text-what-is-the-peformance">
<p>
The error provided by the <code>e1071</code> package when applied to categorical
data is the misclassification rate, hence the expected misclassification
rate, as determined by 10-fold cross validation, is 1/200, making this a
very accurate model for predicting whether or not a cpu is above or
below 500, however, this is a very broad category and the polynomial
model previously had an expected error of aproximately 100 units of
performance, meaning that we would probably expect the polynomial model
to perform just as well in this situation as the SVM.
</p>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
Refer to p. 101 of TB
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2">2</a></sup> <div class="footpara"><p class="footpara">
<a href="https://rpubs.com/therimalaya/43190">https://rpubs.com/therimalaya/43190</a>
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3">3</a></sup> <div class="footpara"><p class="footpara">
<a href="https://www.datacamp.com/community/tutorials/support-vector-machines-r">Data
Camp SVM</a>
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: ryan</p>
<p class="date">Created: 2019-11-19 Tue 13:31</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
