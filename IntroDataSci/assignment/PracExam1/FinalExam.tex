% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Final Exam},
  pdfauthor={Ryan Greenup 1780515},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\lstset{defaultdialect=[5.3]Lua}
\lstset{defaultdialect=[x86masm]Assembler}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\input{/home/ryan/Dropbox/profiles/Template/LaTeX/texnotePreamble.sty}
\renewcommand*\familydefault{\sfdefault}
\usepackage{listings}

\title{Final Exam}
\author{Ryan Greenup 1780515}
\date{24/10/2019}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\hypertarget{import-the-datasets}{%
\subsection{Import the DataSets}\label{import-the-datasets}}

\begin{lstlisting}[language=R]
envDF <- read.csv(file = "./dataset/Envdata(2).csv", header = TRUE, sep = ",") 
knitTable(head(envDF))
\end{lstlisting}

\begin{longtable}[]{@{}lrrrrrrl@{}}
\toprule
patient\_id & co & o3 & no2 & so2 & ppm10 & maxwindspeed &
asthma\tabularnewline
\midrule
\endhead
PJY1ZY7M & 0.4 & 20 & 13 & 0 & 12.9 & 2.1 & TRUE\tabularnewline
PTX0ZI2D & 0.1 & 12 & 6 & 2 & 4.5 & 13.9 & TRUE\tabularnewline
PVX0GR6F & 0.2 & 11 & 9 & 1 & 22.3 & 9.8 & TRUE\tabularnewline
WOE7QE3M & 0.2 & 33 & 2 & 0 & 8.7 & 7.2 & TRUE\tabularnewline
WYU6CP0J & 0.6 & 4 & 15 & 0 & 17.7 & 2.1 & TRUE\tabularnewline
PYU6ZP0K & 0.2 & 15 & 12 & 0 & 10.6 & 13.4 & TRUE\tabularnewline
\bottomrule
\end{longtable}

\begin{lstlisting}[language=R]
admDF <- read.csv(file = "./dataset/Admission(3).csv", header = TRUE, sep = ",")
admDF %>% head() %>% knitTable()
\end{lstlisting}

\begin{longtable}[]{@{}rrrrrrr@{}}
\toprule
Serial.No. & GRE & TOEFL & Uni\_R & SOP & CGPA & Chance\tabularnewline
\midrule
\endhead
93 & 298 & 98 & 2 & 4.0 & 85.29 & 0.34\tabularnewline
377 & 297 & 96 & 2 & 2.5 & 81.72 & 0.34\tabularnewline
59 & 300 & 99 & 1 & 3.0 & 70.99 & 0.36\tabularnewline
95 & 303 & 99 & 3 & 2.0 & 85.83 & 0.36\tabularnewline
92 & 299 & 97 & 3 & 5.0 & 85.83 & 0.38\tabularnewline
376 & 304 & 101 & 2 & 2.0 & 85.83 & 0.38\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{question-1}{%
\section{Question 1}\label{question-1}}

This Question uses the data set ``Envdata''. The data represents the
pollution conditions and maximum wind speed together with the prevalence
of Asthma (present or absent of Asthma) associate with several patients
in Victoria State.

\hypertarget{sub-question-a}{%
\subsection{Sub Question A}\label{sub-question-a}}

\textbf{a. Use K Means Clustering method and identify two clusters with
K=2.}

Now in order to perform \(k\)-menas clustering with \(K=2\) use the
\passthrough{\lstinline!kmeans!} function; Be mindful to remove the
response variable and the primary key:

\begin{lstlisting}[language=R]
envFeat <- subset(envDF, select = -c(patient_id, asthma))
km.out <- kmeans(envFeat, 2, nstart = 20)
\end{lstlisting}

The assignments of the 50 observatoins are contained in
\passthrough{\lstinline!$cluster!} and a summary of the clustering model
is given by:

\begin{lstlisting}[language=R]
km.out
\end{lstlisting}

\begin{lstlisting}
## K-means clustering with 2 clusters of sizes 86, 22
## 
## Cluster means:
##          co       o3      no2       so2    ppm10 maxwindspeed
## 1 0.2279070 15.65116 8.395349 0.6046512 14.30000     5.805814
## 2 0.2090909 31.45455 8.136364 1.2727273 38.66364     6.072727
## 
## Clustering vector:
##   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18 
##   1   1   1   1   1   1   1   1   1   1   2   1   1   1   1   1   1   1 
##  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36 
##   1   1   1   1   1   1   1   1   1   1   1   1   1   2   1   2   1   1 
##  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54 
##   1   1   1   1   1   1   2   1   1   1   1   1   2   1   1   1   1   1 
##  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72 
##   1   2   1   1   2   1   2   1   1   1   1   1   1   1   2   1   2   1 
##  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90 
##   2   1   1   1   1   1   1   2   1   1   2   2   1   1   2   1   2   1 
##  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 
##   1   1   2   1   2   2   2   1   1   2   1   1   1   1   1   2   1   1 
## 
## Within cluster sum of squares by cluster:
## [1] 13622.711  9187.442
##  (between_SS / total_SS =  39.3 %)
## 
## Available components:
## 
## [1] "cluster"      "centers"      "totss"        "withinss"    
## [5] "tot.withinss" "betweenss"    "size"         "iter"        
## [9] "ifault"
\end{lstlisting}

\begin{lstlisting}[language=R]
#km.out$cluster
km2in <- km.out$tot.withinss
km2bet <- km.out$betweenss
\end{lstlisting}

\hypertarget{sub-question-b}{%
\subsection{Sub Question B}\label{sub-question-b}}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  In order to visually display the two clusters obtained in part a, plot
  the first two principal components and colour according to the k-means
  classes. . Compare results obtained in parts ``a and b'' with parts
  ``d and e'' and justify most suitable number of clusters for this data
  set using total within cluster variation and total between cluster
  variation.
\end{enumerate}

\hypertarget{first-perform-pca-in-order-to-reduce-the-dimensions-of-the-clustering}{%
\subsubsection{First Perform PCA in order to reduce the dimensions of
the
clustering:}\label{first-perform-pca-in-order-to-reduce-the-dimensions-of-the-clustering}}

In order to visualise this we will plot the first two principal
components, by default we will choose to scale variables:

\begin{lstlisting}[language=R]
pcaEnvMod <- prcomp(envFeat, scale = TRUE)
pcaEnvMod
\end{lstlisting}

\begin{lstlisting}
## Standard deviations (1, .., p=6):
## [1] 1.4587570 1.2144469 0.9637641 0.8132041 0.7254836 0.5297909
## 
## Rotation (n x k) = (6 x 6):
##                     PC1        PC2        PC3         PC4        PC5
## co           -0.5450045 0.02732184 -0.1096117 -0.31339377  0.7120811
## o3            0.3612149 0.52018122 -0.4198813  0.01863647  0.4073065
## no2          -0.6047801 0.02365796  0.1104536 -0.22452450 -0.2543653
## so2          -0.2997724 0.45848213  0.3808967  0.73427757  0.1111391
## ppm10        -0.1117122 0.69792161 -0.1372112 -0.37152683 -0.4504230
## maxwindspeed  0.3230972 0.17551320  0.7972300 -0.41692930  0.2170425
##                      PC6
## co            0.29143389
## o3           -0.50634875
## no2          -0.71159567
## so2           0.05773126
## ppm10         0.37508112
## maxwindspeed -0.09104995
\end{lstlisting}

This can be plotted:

\begin{lstlisting}[language=R]
# Create the Data Frame
EnvDF <- data.frame(
  envFeat,
  "PredGroup" = km.out$cluster
) %>% as_tibble()


# Create the PCA Model
pcaEnvMod <- prcomp(envFeat, scale = TRUE)

## create a DF of PCA Data
pcaDF <- data.frame(pcaEnvMod$x) %>% as_tibble()
pcaDF$group <-  factor(km.out$cluster)

# Plot the PCA Reduction
ggplot(pcaDF, aes(x = PC1, y=PC2, col = group)) +
  geom_point(size = 4) +
  labs(col = "Predicted\nGroup",
       title = "Clustering visualised using PCA",
       caption = "Circles represent a 90% Confidence Interval from the mean ") +
  theme_classic() +
    stat_ellipse(type = 'norm', level = 0.9, lty = 2) 
\end{lstlisting}

\includegraphics{FinalExam_files/figure-html/unnamed-chunk-5-1.png}

\begin{lstlisting}[language=R]
  # PC11C <- sum(km.out$centers[1,]* pcaEnvMod$rotation[,1])
  # PC21C <- sum(km.out$centers[2,]* pcaEnvMod$rotation[,1])
  # PC12C <- sum(km.out$centers[1,]* pcaEnvMod$rotation[,2])
  # PC22C <- sum(km.out$centers[2,]* pcaEnvMod$rotation[,2])
\end{lstlisting}

\hypertarget{sub-question-c}{%
\subsection{Sub Question C}\label{sub-question-c}}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Construct the misclassification table and misclassification rate and
  discuss the accuracy of predicting presence of Asthma.
\end{enumerate}

\begin{lstlisting}[language=R]
# Now create the confusion Matrix
  # This package prevents making mistakes
#  conf.mat <-   caret::confusionMatrix(data = factor(km.out$cluster), reference = factor(envDF$asthma))
    # We don't know which cluster is truth though...

  # This could otherwise be created by using, always go prediction, reference as a standard
  k2ConfMat <- table("ClusterPred" = km.out$cluster, "Obsered" = envDF$asthma)
 k2ConfMat
\end{lstlisting}

\begin{lstlisting}
##            Obsered
## ClusterPred FALSE TRUE
##           1    47   39
##           2    19    3
\end{lstlisting}

\begin{lstlisting}[language=R]
(k2ConfMat[1,1] +k2ConfMat[2,2])/(sum(k2ConfMat))
\end{lstlisting}

\begin{lstlisting}
## [1] 0.462963
\end{lstlisting}

\begin{lstlisting}[language=R]
 1-(k2ConfMat[1,1] +k2ConfMat[2,2])/(sum(k2ConfMat)) 
\end{lstlisting}

\begin{lstlisting}
## [1] 0.537037
\end{lstlisting}

\begin{lstlisting}[language=R]
  conf.mat <-   caret::confusionMatrix(data = factor(!as.logical(km.out$cluster-1)), reference = factor(envDF$asthma))
  conf.mat$table
\end{lstlisting}

\begin{lstlisting}
##           Reference
## Prediction FALSE TRUE
##      FALSE    19    3
##      TRUE     47   39
\end{lstlisting}

It isn't at first possible to determine the \emph{True Positive},
\emph{False Negative} or misclassificatoin rates because we don't
necessarily know which cluster is indicative of asthma (although for a
reasonably well performing model we take an educated guess), in this
case most of the asthma cases co-incide with cluster 1 and so claster 1
will be taken as indicative of asthma.

The misclassification rate may be hence be calculated by taking the
greater diagonal sum and dividing it by the total (presuming that the
model performs better than mere chance). in this case the
missclassification rate is 54\%:

\[
\text{M}_c = \frac{39+ 19}{47+ 39+ 19+ 3}
\]

\hypertarget{sub-question-d}{%
\subsection{Sub Question D}\label{sub-question-d}}

\textbf{d.~Alternatively use K Means Clustering method to identify three
clusters using K=3.}

In order to perform \(k\)-means to create 3 clusters the code mearly
needs to be amended for this purpose:

Now in order to perform \(k\)-menas clustering with \(K=2\) use the
\passthrough{\lstinline!kmeans!} function; Be mindful to remove the
response variable and the primary key:

\begin{lstlisting}[language=R]
envFeat <- subset(envDF, select = -c(patient_id, asthma))
km.out <- kmeans(envFeat, 3, nstart = 20)
\end{lstlisting}

The assignments of the 50 observatoins are contained in
\passthrough{\lstinline!$cluster!} and a summary of the clustering model
is given by:

\begin{lstlisting}[language=R]
km.out
\end{lstlisting}

\begin{lstlisting}
## K-means clustering with 3 clusters of sizes 64, 23, 21
## 
## Cluster means:
##          co        o3       no2      so2    ppm10 maxwindspeed
## 1 0.1703125 18.859375  5.718750 0.453125 12.76406     6.265625
## 2 0.3956522  6.608696 16.347826 1.043478 19.46522     4.473913
## 3 0.2000000 32.333333  7.571429 1.285714 38.84762     6.142857
## 
## Clustering vector:
##   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18 
##   1   1   2   1   2   1   2   1   2   1   3   1   1   1   1   1   1   2 
##  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36 
##   2   2   2   1   2   1   1   2   1   1   2   1   2   3   1   3   1   2 
##  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54 
##   1   2   1   1   1   1   3   1   1   1   1   1   3   2   1   2   1   2 
##  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72 
##   1   3   1   1   3   1   3   1   1   1   1   1   1   1   3   1   3   1 
##  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90 
##   3   1   1   1   1   1   1   3   2   1   3   3   1   1   3   1   3   1 
##  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 
##   2   1   3   1   3   3   3   1   1   3   1   1   2   2   1   2   1   2 
## 
## Within cluster sum of squares by cluster:
## [1] 5456.977 3451.198 8665.179
##  (between_SS / total_SS =  53.3 %)
## 
## Available components:
## 
## [1] "cluster"      "centers"      "totss"        "withinss"    
## [5] "tot.withinss" "betweenss"    "size"         "iter"        
## [9] "ifault"
\end{lstlisting}

\begin{lstlisting}[language=R]
#km.out$cluster
km3in  <- km.out$tot.withinss
km3bet <- km.out$betweenss
\end{lstlisting}

\hypertarget{sub-question-e}{%
\subsection{Sub Question E}\label{sub-question-e}}

\textbf{e. In order to visually display the three clusters obtained in
part d, plot the first two principal components and colour according to
the k-means classes.}

Again merely ammending the above code to reflect three clusters:

\begin{lstlisting}[language=R]
pcaEnvMod <- prcomp(envFeat, scale = TRUE)
pcaEnvMod
\end{lstlisting}

\begin{lstlisting}
## Standard deviations (1, .., p=6):
## [1] 1.4587570 1.2144469 0.9637641 0.8132041 0.7254836 0.5297909
## 
## Rotation (n x k) = (6 x 6):
##                     PC1        PC2        PC3         PC4        PC5
## co           -0.5450045 0.02732184 -0.1096117 -0.31339377  0.7120811
## o3            0.3612149 0.52018122 -0.4198813  0.01863647  0.4073065
## no2          -0.6047801 0.02365796  0.1104536 -0.22452450 -0.2543653
## so2          -0.2997724 0.45848213  0.3808967  0.73427757  0.1111391
## ppm10        -0.1117122 0.69792161 -0.1372112 -0.37152683 -0.4504230
## maxwindspeed  0.3230972 0.17551320  0.7972300 -0.41692930  0.2170425
##                      PC6
## co            0.29143389
## o3           -0.50634875
## no2          -0.71159567
## so2           0.05773126
## ppm10         0.37508112
## maxwindspeed -0.09104995
\end{lstlisting}

This can be plotted:

\begin{lstlisting}[language=R]
# Create the Data Frame
EnvDF <- data.frame(
  envFeat,
  "PredGroup" = km.out$cluster
) %>% as_tibble()


# Create the PCA Model
pcaEnvMod <- prcomp(envFeat, scale = TRUE)

## create a DF of PCA Data
pcaDF <- data.frame(pcaEnvMod$x) %>% as_tibble()
pcaDF$group <-  factor(km.out$cluster)

# Plot the PCA Reduction
ggplot(pcaDF, aes(x = PC1, y=PC2, col = group)) +
  geom_point(size = 4) +
  labs(col = "Predicted\nGroup",
       title = "Clustering visualised using PCA",
       caption = "Circles represent a 90% Confidence Interval from the mean ") +
  theme_classic() +
    stat_ellipse(type = 'norm', level = 0.9, lty = 2) 
\end{lstlisting}

\includegraphics{FinalExam_files/figure-html/unnamed-chunk-10-1.png}

\begin{lstlisting}[language=R]
  km2in
\end{lstlisting}

\begin{lstlisting}
## [1] 22810.15
\end{lstlisting}

\begin{lstlisting}[language=R]
  km3in
\end{lstlisting}

\begin{lstlisting}
## [1] 17573.35
\end{lstlisting}

\begin{lstlisting}[language=R]
  km2bet
\end{lstlisting}

\begin{lstlisting}
## [1] 14784.2
\end{lstlisting}

\begin{lstlisting}[language=R]
  km3bet
\end{lstlisting}

\begin{lstlisting}
## [1] 20021
\end{lstlisting}

Although in this case it isn't necessarily clear what the 3rd category
may be, perhaps at risk of developing asthma, an investigation into the
biplot of the PC's may allow further interpretation.

\hypertarget{sub-question-f}{%
\subsection{Sub Question F}\label{sub-question-f}}

\textbf{f.~Compare results obtained in parts ``a and b'' with parts ``d
and e'' and justify most suitable number of clusters for this data set
using total within cluster variation and total between cluster
variation.}

\begin{itemize}
\tightlist
\item
  Within Cluster Variation
\item
  The within cluster variation corresponding to a 2-cluster model is:
  22, 810
\item
  The within cluster variation corresponding to a 3-cluster model is:
  17, 573
\item
  Between Cluster Variation
\item
  The between cluster variation corresponding to a 2-cluster model is:
  14, 784
\item
  The between cluster variation corresponding to a 3-cluster model is:
  20, 021
\end{itemize}

The 3-cluster model reduces the squared error from 22K to 17K and
increases the between cluster variation from 20k to 14k, this is good
evidence to suggest that there may indeed be 3 distinct groups rather
than 2 and hence a 3 cluster model is chosen rather than 2.

\hypertarget{question-2}{%
\section{Question 2}\label{question-2}}

** This Question uses the data set ``Envdata'' used in Question 1**

\hypertarget{sub-question-1}{%
\subsubsection{Sub-Question 1}\label{sub-question-1}}

\textbf{a. Calculate the mean and the variance for each variable and
discuss if scaling is necessary and justify your findings.}

Looking at the mean values and variance:

\begin{lstlisting}[language=R]
desc.stats <- data.frame(
Mean = apply(envFeat, 2, mean), # 1 is rows, 2 is cols p. 401 ISL TB
Variance = apply(envFeat, 2, var) # 1 is rows, 2 is cols p. 401 ISL TB
)
desc.stats$variable <- row.names(desc.stats)

descStatsTidy <- pivot_longer(desc.stats, cols = c(Mean, Variance), names_to = "Statistic", values_to = "Value")

ggplot(descStatsTidy, aes(x = variable, y = Value, fill = Statistic)) +
  geom_col(position = "dodge") +
  theme_classic() +
  labs(title = "Descriptive Stats")
\end{lstlisting}

\includegraphics{FinalExam_files/figure-html/unnamed-chunk-11-1.png}

It can Clearly be seen that the variance for particulate matter
\passthrough{\lstinline!ppm10!} is extremely large and hence we will
choose to scale the data.

\begin{lstlisting}
b. Apply scaling and derive the principal components. (R code and output)

c. Give the Scree Plot and give the percentage variation captured by each principal component.

d. Select the number of principal components most suitable to represent the dataset and justify your answer.

e. Derive and give the principal component loading vectors for the given dataset and explain the results/output.
\end{lstlisting}

\hypertarget{question-3}{%
\section{Question 3}\label{question-3}}

\[
\begin{align}
\text{H}_0: \enspace \beta = 0 \enspace \text{The Slope Parameter is not significantly different from 0} \\
\text{H}_a: \enspace \beta \neq 0 \enspace \text{The Slope Parameter \textbf{is} significantly different from 0} 
\end{align}
\]

\hypertarget{use-pandoc-to-create-pdf}{%
\section{Use Pandoc to Create PDF}\label{use-pandoc-to-create-pdf}}

\end{document}
